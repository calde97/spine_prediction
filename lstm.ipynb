{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "df_train = pd.read_csv('preprocess_data/train.csv')\n",
    "df_validation = pd.read_csv('preprocess_data/validation.csv')\n",
    "\n",
    "x_train_df = df_train[df_train.columns.drop(list(df_train.filter(regex='Spine')))]\n",
    "y_train_df = df_train[list(df_train.filter(regex='Spine'))]\n",
    "y_train_df['id'] = df_train['id']\n",
    "\n",
    "\n",
    "x_validation_df = df_validation[df_validation.columns.drop(list(df_validation.filter(regex='Spine')))]\n",
    "y_validation_df = df_validation[list(df_validation.filter(regex='Spine'))]\n",
    "y_validation_df['id'] = df_validation['id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "sequence_length = 1\n",
    "\n",
    "ids = x_train_df['id'].unique()\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "lengths = []\n",
    "\n",
    "for id in ids:\n",
    "    df_single_id = x_train_df[x_train_df['id'] == id]\n",
    "    number_of_frames = df_single_id.shape[0]\n",
    "    x_animation = []\n",
    "    \n",
    "    quotient = number_of_frames // sequence_length\n",
    "    remainder = number_of_frames % sequence_length\n",
    "    \n",
    "    df_single_id_x = df_single_id.drop(['id', 'Frame'], axis=1)\n",
    "    \n",
    "    # take the values spine from df_single_id\n",
    "    df_single_id_y = y_train_df[y_train_df['id'] == id]\n",
    "    df_single_id_y = df_single_id_y.drop(['id'], axis=1)\n",
    "    \n",
    "    for i in range(quotient):\n",
    "        x_train.append(torch.tensor(df_single_id_x.iloc[i*sequence_length:(i+1)*sequence_length].values, dtype=torch.float32))\n",
    "        y_train.append(torch.tensor(df_single_id_y.iloc[(i+1)*sequence_length-1].values, dtype=torch.float32))\n",
    "        lengths.append(sequence_length)\n",
    "        \n",
    "    if remainder != 0:\n",
    "        padded = torch.zeros(sequence_length, df_single_id_x.shape[1])\n",
    "        padded[:remainder] = torch.tensor(df_single_id_x.iloc[-remainder:].values, dtype=torch.float32)\n",
    "        y_train.append(torch.tensor(df_single_id_y.iloc[quotient*sequence_length + remainder - 1 ].values, dtype=torch.float32))\n",
    "        x_train.append(padded)\n",
    "        lengths.append(remainder)\n",
    "        \n",
    "x_train = torch.stack(x_train)\n",
    "y_train = torch.stack(y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T20:16:24.544476228Z",
     "start_time": "2023-08-29T20:16:24.373771187Z"
    }
   },
   "id": "a39fe61c14f4ff45"
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "# shuffle the data around first axes \n",
    "indices = torch.randperm(x_train.shape[0])\n",
    "x_train = x_train[indices]\n",
    "y_train = y_train[indices]\n",
    "lengths = torch.tensor(lengths)[indices]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T20:16:29.435426750Z",
     "start_time": "2023-08-29T20:16:29.424232930Z"
    }
   },
   "id": "d1360e87a054fb19"
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "ids = x_validation_df['id'].unique()\n",
    "\n",
    "x_validation = []\n",
    "y_validation = []\n",
    "lengths_val = []\n",
    "\n",
    "for id in ids:\n",
    "    df_single_id = x_validation_df[x_validation_df['id'] == id]\n",
    "    number_of_frames = df_single_id.shape[0]\n",
    "    x_animation = []\n",
    "    \n",
    "    quotient = number_of_frames // sequence_length\n",
    "    remainder = number_of_frames % sequence_length\n",
    "    \n",
    "    df_single_id_x = df_single_id.drop(['id', 'Frame'], axis=1)\n",
    "    \n",
    "    # take the values spine from df_single_id\n",
    "    df_single_id_y = y_validation_df[y_validation_df['id'] == id]\n",
    "    df_single_id_y = df_single_id_y.drop(['id'], axis=1)\n",
    "    \n",
    "    for i in range(quotient):\n",
    "        x_validation.append(torch.tensor(df_single_id_x.iloc[i*sequence_length:(i+1)*sequence_length].values, dtype=torch.float32))\n",
    "        y_validation.append(torch.tensor(df_single_id_y.iloc[(i+1)*sequence_length-1].values, dtype=torch.float32))\n",
    "        lengths_val.append(sequence_length)\n",
    "        \n",
    "    if remainder != 0:\n",
    "        padded = torch.zeros(sequence_length, df_single_id_x.shape[1])\n",
    "        padded[:remainder] = torch.tensor(df_single_id_x.iloc[-remainder:].values, dtype=torch.float32)\n",
    "        y_validation.append(torch.tensor(df_single_id_y.iloc[quotient*sequence_length + remainder - 1 ].values, dtype=torch.float32))\n",
    "        x_validation.append(padded)\n",
    "        lengths_val.append(remainder)\n",
    "        \n",
    "x_validation = torch.stack(x_validation)\n",
    "y_validation = torch.stack(y_validation)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T20:16:30.703433844Z",
     "start_time": "2023-08-29T20:16:30.657475948Z"
    }
   },
   "id": "b901941fa37c71c"
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        data = pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
    "        #data = x\n",
    "        out, _ = self.lstm(data)\n",
    "        # add dropout\n",
    "        out, _ = torch.nn.utils.rnn.pad_packed_sequence(out, batch_first=True)\n",
    "        #out = self.fc2(out)\n",
    "        #out = torch.relu(out)\n",
    "        out = self.fc(out[:, -1, :])  # Get output from the last time step\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T20:23:37.257898264Z",
     "start_time": "2023-08-29T20:23:37.241112412Z"
    }
   },
   "id": "7c70e1f81546117d"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/10000], Training Loss: 1.1244455576, Validation Loss: 0.6902565360\n",
      "Epoch [40/10000], Training Loss: 0.8598522544, Validation Loss: 0.5584358573\n",
      "Epoch [60/10000], Training Loss: 0.6518928409, Validation Loss: 0.4376107156\n",
      "Epoch [80/10000], Training Loss: 0.5113423467, Validation Loss: 0.3630029857\n",
      "Epoch [100/10000], Training Loss: 0.4081244469, Validation Loss: 0.3108651042\n",
      "Epoch [120/10000], Training Loss: 0.3319714963, Validation Loss: 0.2646967471\n",
      "Epoch [140/10000], Training Loss: 0.2832886279, Validation Loss: 0.2295845002\n",
      "Epoch [160/10000], Training Loss: 0.2433966547, Validation Loss: 0.1983471662\n",
      "Epoch [180/10000], Training Loss: 0.2057455778, Validation Loss: 0.1681747139\n",
      "Epoch [200/10000], Training Loss: 0.1785031855, Validation Loss: 0.1445733905\n",
      "Epoch [220/10000], Training Loss: 0.1571953297, Validation Loss: 0.1258459985\n",
      "Epoch [240/10000], Training Loss: 0.1394940168, Validation Loss: 0.1115760952\n",
      "Epoch [260/10000], Training Loss: 0.1245974898, Validation Loss: 0.0989899114\n",
      "Epoch [280/10000], Training Loss: 0.1119114310, Validation Loss: 0.0887851566\n",
      "Epoch [300/10000], Training Loss: 0.1011870280, Validation Loss: 0.0804611146\n",
      "Epoch [320/10000], Training Loss: 0.0917052403, Validation Loss: 0.0737770423\n",
      "Epoch [340/10000], Training Loss: 0.0837929025, Validation Loss: 0.0681795776\n",
      "Epoch [360/10000], Training Loss: 0.0768935159, Validation Loss: 0.0630285218\n",
      "Epoch [380/10000], Training Loss: 0.0707304925, Validation Loss: 0.0584556572\n",
      "Epoch [400/10000], Training Loss: 0.0651946664, Validation Loss: 0.0550240986\n",
      "Epoch [420/10000], Training Loss: 0.0600381196, Validation Loss: 0.0528504364\n",
      "Epoch [440/10000], Training Loss: 0.0554006658, Validation Loss: 0.0506871529\n",
      "Epoch [460/10000], Training Loss: 0.0513341017, Validation Loss: 0.0482385047\n",
      "Epoch [480/10000], Training Loss: 0.0478036813, Validation Loss: 0.0455558747\n",
      "Epoch [500/10000], Training Loss: 0.0446439050, Validation Loss: 0.0431527346\n",
      "Epoch [520/10000], Training Loss: 0.0417718478, Validation Loss: 0.0409837030\n",
      "Epoch [540/10000], Training Loss: 0.0391317233, Validation Loss: 0.0388628580\n",
      "Epoch [560/10000], Training Loss: 0.0366737954, Validation Loss: 0.0368712768\n",
      "Epoch [580/10000], Training Loss: 0.0343768746, Validation Loss: 0.0350925215\n",
      "Epoch [600/10000], Training Loss: 0.0322494879, Validation Loss: 0.0335538536\n",
      "Epoch [620/10000], Training Loss: 0.0302895457, Validation Loss: 0.0322601870\n",
      "Epoch [640/10000], Training Loss: 0.0284855161, Validation Loss: 0.0312192403\n",
      "Epoch [660/10000], Training Loss: 0.0268240441, Validation Loss: 0.0303871781\n",
      "Epoch [680/10000], Training Loss: 0.0252909325, Validation Loss: 0.0297128092\n",
      "Epoch [700/10000], Training Loss: 0.0238718949, Validation Loss: 0.0291488916\n",
      "Epoch [720/10000], Training Loss: 0.0225547738, Validation Loss: 0.0286729224\n",
      "Epoch [740/10000], Training Loss: 0.0213284548, Validation Loss: 0.0282691382\n",
      "Epoch [760/10000], Training Loss: 0.0201801993, Validation Loss: 0.0279212948\n",
      "Epoch [780/10000], Training Loss: 0.0191040486, Validation Loss: 0.0275830869\n",
      "Epoch [800/10000], Training Loss: 0.0181017220, Validation Loss: 0.0271677915\n",
      "Epoch [820/10000], Training Loss: 0.0171637610, Validation Loss: 0.0267283712\n",
      "Epoch [840/10000], Training Loss: 0.0162523910, Validation Loss: 0.0262971334\n",
      "Epoch [860/10000], Training Loss: 0.0151085155, Validation Loss: 0.0260230489\n",
      "Epoch [880/10000], Training Loss: 0.0142025417, Validation Loss: 0.0262322538\n",
      "Epoch [900/10000], Training Loss: 0.0133693339, Validation Loss: 0.0266223308\n",
      "Epoch [920/10000], Training Loss: 0.0126277953, Validation Loss: 0.0264334437\n",
      "Epoch [940/10000], Training Loss: 0.0119381566, Validation Loss: 0.0261035673\n",
      "Epoch [960/10000], Training Loss: 0.0112891272, Validation Loss: 0.0257149972\n",
      "Epoch [980/10000], Training Loss: 0.0106721492, Validation Loss: 0.0253442246\n",
      "Epoch [1000/10000], Training Loss: 0.0100819459, Validation Loss: 0.0250054728\n",
      "Epoch [1020/10000], Training Loss: 0.0095142657, Validation Loss: 0.0246937163\n",
      "Epoch [1040/10000], Training Loss: 0.0089615220, Validation Loss: 0.0244031008\n",
      "Epoch [1060/10000], Training Loss: 0.0084351758, Validation Loss: 0.0240674838\n",
      "Epoch [1080/10000], Training Loss: 0.0079550128, Validation Loss: 0.0235887114\n",
      "Epoch [1100/10000], Training Loss: 0.0074922494, Validation Loss: 0.0231161937\n",
      "Epoch [1120/10000], Training Loss: 0.0070610153, Validation Loss: 0.0226528812\n",
      "Epoch [1140/10000], Training Loss: 0.0066550765, Validation Loss: 0.0223270319\n",
      "Epoch [1160/10000], Training Loss: 0.0062702009, Validation Loss: 0.0222088788\n",
      "Epoch [1180/10000], Training Loss: 0.0059129857, Validation Loss: 0.0222550314\n",
      "Epoch [1200/10000], Training Loss: 0.0055496823, Validation Loss: 0.0224439725\n",
      "Epoch [1220/10000], Training Loss: 0.0052200919, Validation Loss: 0.0223912429\n",
      "Epoch [1240/10000], Training Loss: 0.0049101077, Validation Loss: 0.0223363154\n",
      "Epoch [1260/10000], Training Loss: 0.0046279789, Validation Loss: 0.0223835297\n",
      "Epoch [1280/10000], Training Loss: 0.0043440321, Validation Loss: 0.0222053230\n",
      "Epoch [1300/10000], Training Loss: 0.0040850220, Validation Loss: 0.0221624020\n",
      "Epoch [1320/10000], Training Loss: 0.0038416600, Validation Loss: 0.0221002344\n",
      "Epoch [1340/10000], Training Loss: 0.0036123865, Validation Loss: 0.0220600031\n",
      "Epoch [1360/10000], Training Loss: 0.0034003283, Validation Loss: 0.0219421629\n",
      "Epoch [1380/10000], Training Loss: 0.0031952907, Validation Loss: 0.0219471399\n",
      "Epoch [1400/10000], Training Loss: 0.0030031956, Validation Loss: 0.0218957458\n",
      "Epoch [1420/10000], Training Loss: 0.0028238376, Validation Loss: 0.0218327288\n",
      "Epoch [1440/10000], Training Loss: 0.0026549578, Validation Loss: 0.0217789710\n",
      "Epoch [1460/10000], Training Loss: 0.0024979475, Validation Loss: 0.0216181334\n",
      "Epoch [1480/10000], Training Loss: 0.0023508717, Validation Loss: 0.0215655304\n",
      "Epoch [1500/10000], Training Loss: 0.0022092799, Validation Loss: 0.0215186458\n",
      "Epoch [1520/10000], Training Loss: 0.0020782785, Validation Loss: 0.0214668121\n",
      "Epoch [1540/10000], Training Loss: 0.0019555811, Validation Loss: 0.0214020759\n",
      "Epoch [1560/10000], Training Loss: 0.0018406113, Validation Loss: 0.0213489141\n",
      "Epoch [1580/10000], Training Loss: 0.0017509783, Validation Loss: 0.0214149058\n",
      "Epoch [1600/10000], Training Loss: 0.0016371373, Validation Loss: 0.0211804323\n",
      "Epoch [1620/10000], Training Loss: 0.0015390008, Validation Loss: 0.0211792029\n",
      "Epoch [1640/10000], Training Loss: 0.0014507223, Validation Loss: 0.0211193208\n",
      "Epoch [1660/10000], Training Loss: 0.0013683938, Validation Loss: 0.0210798495\n",
      "Epoch [1680/10000], Training Loss: 0.0012915439, Validation Loss: 0.0210451521\n",
      "Epoch [1700/10000], Training Loss: 0.0012488510, Validation Loss: 0.0210788473\n",
      "Epoch [1720/10000], Training Loss: 0.0011567866, Validation Loss: 0.0209032707\n",
      "Epoch [1740/10000], Training Loss: 0.0010911238, Validation Loss: 0.0209204368\n",
      "Epoch [1760/10000], Training Loss: 0.0010324157, Validation Loss: 0.0208759904\n",
      "Epoch [1780/10000], Training Loss: 0.0009780014, Validation Loss: 0.0208412018\n",
      "Epoch [1800/10000], Training Loss: 0.0009276320, Validation Loss: 0.0208215974\n",
      "Epoch [1820/10000], Training Loss: 0.0008902978, Validation Loss: 0.0206753891\n",
      "Epoch [1840/10000], Training Loss: 0.0008365577, Validation Loss: 0.0207457580\n",
      "Epoch [1860/10000], Training Loss: 0.0007952439, Validation Loss: 0.0207052138\n",
      "Epoch [1880/10000], Training Loss: 0.0007568245, Validation Loss: 0.0206781942\n",
      "Epoch [1900/10000], Training Loss: 0.0007211068, Validation Loss: 0.0206438173\n",
      "Epoch [1920/10000], Training Loss: 0.0007003347, Validation Loss: 0.0205388181\n",
      "Epoch [1940/10000], Training Loss: 0.0006621564, Validation Loss: 0.0205315873\n",
      "Epoch [1960/10000], Training Loss: 0.0006283431, Validation Loss: 0.0205705576\n",
      "Epoch [1980/10000], Training Loss: 0.0006012783, Validation Loss: 0.0205489006\n",
      "Epoch [2000/10000], Training Loss: 0.0005760535, Validation Loss: 0.0205227397\n",
      "Epoch [2020/10000], Training Loss: 0.0005526442, Validation Loss: 0.0205112528\n",
      "Epoch [2040/10000], Training Loss: 0.0005591502, Validation Loss: 0.0205501374\n",
      "Epoch [2060/10000], Training Loss: 0.0005130083, Validation Loss: 0.0204112772\n",
      "Epoch [2080/10000], Training Loss: 0.0004913156, Validation Loss: 0.0204409193\n",
      "Epoch [2100/10000], Training Loss: 0.0004735189, Validation Loss: 0.0204296000\n",
      "Epoch [2120/10000], Training Loss: 0.0004567891, Validation Loss: 0.0204097591\n",
      "Epoch [2140/10000], Training Loss: 0.0004411391, Validation Loss: 0.0204003416\n",
      "Epoch [2160/10000], Training Loss: 0.0004424684, Validation Loss: 0.0204718783\n",
      "Epoch [2180/10000], Training Loss: 0.0004177795, Validation Loss: 0.0203611180\n",
      "Epoch [2200/10000], Training Loss: 0.0004007225, Validation Loss: 0.0203178842\n",
      "Epoch [2220/10000], Training Loss: 0.0003878441, Validation Loss: 0.0203264132\n",
      "Epoch [2240/10000], Training Loss: 0.0003764190, Validation Loss: 0.0203136485\n",
      "Epoch [2260/10000], Training Loss: 0.0003656498, Validation Loss: 0.0203049742\n",
      "Epoch [2280/10000], Training Loss: 0.0003557000, Validation Loss: 0.0203012712\n",
      "Epoch [2300/10000], Training Loss: 0.0003519030, Validation Loss: 0.0201751553\n",
      "Epoch [2320/10000], Training Loss: 0.0003376615, Validation Loss: 0.0202577729\n",
      "Epoch [2340/10000], Training Loss: 0.0003285065, Validation Loss: 0.0202310421\n",
      "Epoch [2360/10000], Training Loss: 0.0003204390, Validation Loss: 0.0202199090\n",
      "Epoch [2380/10000], Training Loss: 0.0003127233, Validation Loss: 0.0202084742\n",
      "Epoch [2400/10000], Training Loss: 0.0003054140, Validation Loss: 0.0201962478\n",
      "Epoch [2420/10000], Training Loss: 0.0002986662, Validation Loss: 0.0201811865\n",
      "Epoch [2440/10000], Training Loss: 0.0003209845, Validation Loss: 0.0200872123\n",
      "Epoch [2460/10000], Training Loss: 0.0002868131, Validation Loss: 0.0200978797\n",
      "Epoch [2480/10000], Training Loss: 0.0002800376, Validation Loss: 0.0201160554\n",
      "Epoch [2500/10000], Training Loss: 0.0002740206, Validation Loss: 0.0201058667\n",
      "Epoch [2520/10000], Training Loss: 0.0002685272, Validation Loss: 0.0200869087\n",
      "Epoch [2540/10000], Training Loss: 0.0002632701, Validation Loss: 0.0200713295\n",
      "Epoch [2560/10000], Training Loss: 0.0002582116, Validation Loss: 0.0200542938\n",
      "Epoch [2580/10000], Training Loss: 0.0002533754, Validation Loss: 0.0200343728\n",
      "Epoch [2600/10000], Training Loss: 0.0002906362, Validation Loss: 0.0199287422\n",
      "Epoch [2620/10000], Training Loss: 0.0002454326, Validation Loss: 0.0199557692\n",
      "Epoch [2640/10000], Training Loss: 0.0002400477, Validation Loss: 0.0199587233\n",
      "Epoch [2660/10000], Training Loss: 0.0002358444, Validation Loss: 0.0199382473\n",
      "Epoch [2680/10000], Training Loss: 0.0002318442, Validation Loss: 0.0199192874\n",
      "Epoch [2700/10000], Training Loss: 0.0002279409, Validation Loss: 0.0199015439\n",
      "Epoch [2720/10000], Training Loss: 0.0002241629, Validation Loss: 0.0198825151\n",
      "Epoch [2740/10000], Training Loss: 0.0002204954, Validation Loss: 0.0198622439\n",
      "Epoch [2760/10000], Training Loss: 0.0002174567, Validation Loss: 0.0198493302\n",
      "Epoch [2780/10000], Training Loss: 0.0002156042, Validation Loss: 0.0197347272\n",
      "Epoch [2800/10000], Training Loss: 0.0002136242, Validation Loss: 0.0197825115\n",
      "Epoch [2820/10000], Training Loss: 0.0002075841, Validation Loss: 0.0197394621\n",
      "Epoch [2840/10000], Training Loss: 0.0002040262, Validation Loss: 0.0197323188\n",
      "Epoch [2860/10000], Training Loss: 0.0002009183, Validation Loss: 0.0197058097\n",
      "Epoch [2880/10000], Training Loss: 0.0001979442, Validation Loss: 0.0196849294\n",
      "Epoch [2900/10000], Training Loss: 0.0001950408, Validation Loss: 0.0196627006\n",
      "Epoch [2920/10000], Training Loss: 0.0001922039, Validation Loss: 0.0196394194\n",
      "Epoch [2940/10000], Training Loss: 0.0001894309, Validation Loss: 0.0196152069\n",
      "Epoch [2960/10000], Training Loss: 0.0002093552, Validation Loss: 0.0195130501\n",
      "Epoch [2980/10000], Training Loss: 0.0001913775, Validation Loss: 0.0195499901\n",
      "Epoch [3000/10000], Training Loss: 0.0001820591, Validation Loss: 0.0195047390\n",
      "Epoch [3020/10000], Training Loss: 0.0001792299, Validation Loss: 0.0194948837\n",
      "Epoch [3040/10000], Training Loss: 0.0001767830, Validation Loss: 0.0194724817\n",
      "Epoch [3060/10000], Training Loss: 0.0001743891, Validation Loss: 0.0194477439\n",
      "Epoch [3080/10000], Training Loss: 0.0001720553, Validation Loss: 0.0194232389\n",
      "Epoch [3100/10000], Training Loss: 0.0001697647, Validation Loss: 0.0193981249\n",
      "Epoch [3120/10000], Training Loss: 0.0001675560, Validation Loss: 0.0193746965\n",
      "Epoch [3140/10000], Training Loss: 0.0001727294, Validation Loss: 0.0192545056\n",
      "Epoch [3160/10000], Training Loss: 0.0001677056, Validation Loss: 0.0192653183\n",
      "Epoch [3180/10000], Training Loss: 0.0001612740, Validation Loss: 0.0192531180\n",
      "Epoch [3200/10000], Training Loss: 0.0001592131, Validation Loss: 0.0192330331\n",
      "Epoch [3220/10000], Training Loss: 0.0001571752, Validation Loss: 0.0192090385\n",
      "Epoch [3240/10000], Training Loss: 0.0001552095, Validation Loss: 0.0191838909\n",
      "Epoch [3260/10000], Training Loss: 0.0001532723, Validation Loss: 0.0191583112\n",
      "Epoch [3280/10000], Training Loss: 0.0001513663, Validation Loss: 0.0191323943\n",
      "Epoch [3300/10000], Training Loss: 0.0001494900, Validation Loss: 0.0191064086\n",
      "Epoch [3320/10000], Training Loss: 0.0001476423, Validation Loss: 0.0190805718\n",
      "Epoch [3340/10000], Training Loss: 0.0001568204, Validation Loss: 0.0190910213\n",
      "Epoch [3360/10000], Training Loss: 0.0001458116, Validation Loss: 0.0188938640\n",
      "Epoch [3380/10000], Training Loss: 0.0001425990, Validation Loss: 0.0189246889\n",
      "Epoch [3400/10000], Training Loss: 0.0001409303, Validation Loss: 0.0189358033\n",
      "Epoch [3420/10000], Training Loss: 0.0001391215, Validation Loss: 0.0189120155\n",
      "Epoch [3440/10000], Training Loss: 0.0001374759, Validation Loss: 0.0188842453\n",
      "Epoch [3460/10000], Training Loss: 0.0001358606, Validation Loss: 0.0188598596\n",
      "Epoch [3480/10000], Training Loss: 0.0001342714, Validation Loss: 0.0188337695\n",
      "Epoch [3500/10000], Training Loss: 0.0001327036, Validation Loss: 0.0188078377\n",
      "Epoch [3520/10000], Training Loss: 0.0001311863, Validation Loss: 0.0187803060\n",
      "Epoch [3540/10000], Training Loss: 0.0001424438, Validation Loss: 0.0188204907\n",
      "Epoch [3560/10000], Training Loss: 0.0001305118, Validation Loss: 0.0186938550\n",
      "Epoch [3580/10000], Training Loss: 0.0001272839, Validation Loss: 0.0186932832\n",
      "Epoch [3600/10000], Training Loss: 0.0001273526, Validation Loss: 0.0186752919\n",
      "Epoch [3620/10000], Training Loss: 0.0001269534, Validation Loss: 0.0185881052\n",
      "Epoch [3640/10000], Training Loss: 0.0001224733, Validation Loss: 0.0185836442\n",
      "Epoch [3660/10000], Training Loss: 0.0001213006, Validation Loss: 0.0185738187\n",
      "Epoch [3680/10000], Training Loss: 0.0001199470, Validation Loss: 0.0185491126\n",
      "Epoch [3700/10000], Training Loss: 0.0001483237, Validation Loss: 0.0185223538\n",
      "Epoch [3720/10000], Training Loss: 0.0001200420, Validation Loss: 0.0184544530\n",
      "Epoch [3740/10000], Training Loss: 0.0001161159, Validation Loss: 0.0184469093\n",
      "Epoch [3760/10000], Training Loss: 0.0001145886, Validation Loss: 0.0184284281\n",
      "Epoch [3780/10000], Training Loss: 0.0001133364, Validation Loss: 0.0184001718\n",
      "Epoch [3800/10000], Training Loss: 0.0001232176, Validation Loss: 0.0183756854\n",
      "Epoch [3820/10000], Training Loss: 0.0001121596, Validation Loss: 0.0182945207\n",
      "Epoch [3840/10000], Training Loss: 0.0001107448, Validation Loss: 0.0182873886\n",
      "Epoch [3860/10000], Training Loss: 0.0001085653, Validation Loss: 0.0182763636\n",
      "Epoch [3880/10000], Training Loss: 0.0001073161, Validation Loss: 0.0182521176\n",
      "Epoch [3900/10000], Training Loss: 0.0001061392, Validation Loss: 0.0182289928\n",
      "Epoch [3920/10000], Training Loss: 0.0001184050, Validation Loss: 0.0181485992\n",
      "Epoch [3940/10000], Training Loss: 0.0001109611, Validation Loss: 0.0181692988\n",
      "Epoch [3960/10000], Training Loss: 0.0001036412, Validation Loss: 0.0181281213\n",
      "Epoch [3980/10000], Training Loss: 0.0001018130, Validation Loss: 0.0181126166\n",
      "Epoch [4000/10000], Training Loss: 0.0001006527, Validation Loss: 0.0180919021\n",
      "Epoch [4020/10000], Training Loss: 0.0001001997, Validation Loss: 0.0180686247\n",
      "Epoch [4040/10000], Training Loss: 0.0001099539, Validation Loss: 0.0179791227\n",
      "Epoch [4060/10000], Training Loss: 0.0000985957, Validation Loss: 0.0179455429\n",
      "Epoch [4080/10000], Training Loss: 0.0000966290, Validation Loss: 0.0179701950\n",
      "Epoch [4100/10000], Training Loss: 0.0000955729, Validation Loss: 0.0179511160\n",
      "Epoch [4120/10000], Training Loss: 0.0000945634, Validation Loss: 0.0179280713\n",
      "Epoch [4140/10000], Training Loss: 0.0000935820, Validation Loss: 0.0179065783\n",
      "Epoch [4160/10000], Training Loss: 0.0000927301, Validation Loss: 0.0178881306\n",
      "Epoch [4180/10000], Training Loss: 0.0000940894, Validation Loss: 0.0177448038\n",
      "Epoch [4200/10000], Training Loss: 0.0000933091, Validation Loss: 0.0177509077\n",
      "Epoch [4220/10000], Training Loss: 0.0000899836, Validation Loss: 0.0177829992\n",
      "Epoch [4240/10000], Training Loss: 0.0000890329, Validation Loss: 0.0177509934\n",
      "Epoch [4260/10000], Training Loss: 0.0000880802, Validation Loss: 0.0177354570\n",
      "Epoch [4280/10000], Training Loss: 0.0000871848, Validation Loss: 0.0177160371\n",
      "Epoch [4300/10000], Training Loss: 0.0000863048, Validation Loss: 0.0176969804\n",
      "Epoch [4320/10000], Training Loss: 0.0000854353, Validation Loss: 0.0176779907\n",
      "Epoch [4340/10000], Training Loss: 0.0000877073, Validation Loss: 0.0176660605\n",
      "Epoch [4360/10000], Training Loss: 0.0000863004, Validation Loss: 0.0175456572\n",
      "Epoch [4380/10000], Training Loss: 0.0000846349, Validation Loss: 0.0175528936\n",
      "Epoch [4400/10000], Training Loss: 0.0000823315, Validation Loss: 0.0175592937\n",
      "Epoch [4420/10000], Training Loss: 0.0000813181, Validation Loss: 0.0175459329\n",
      "Epoch [4440/10000], Training Loss: 0.0000805806, Validation Loss: 0.0175346900\n",
      "Epoch [4460/10000], Training Loss: 0.0000854912, Validation Loss: 0.0175159499\n",
      "Epoch [4480/10000], Training Loss: 0.0000794686, Validation Loss: 0.0174708068\n",
      "Epoch [4500/10000], Training Loss: 0.0000782649, Validation Loss: 0.0174769480\n",
      "Epoch [4520/10000], Training Loss: 0.0000784036, Validation Loss: 0.0174670853\n",
      "Epoch [4540/10000], Training Loss: 0.0000862258, Validation Loss: 0.0173340160\n",
      "Epoch [4560/10000], Training Loss: 0.0000769883, Validation Loss: 0.0173372868\n",
      "Epoch [4580/10000], Training Loss: 0.0000752544, Validation Loss: 0.0173627995\n",
      "Epoch [4600/10000], Training Loss: 0.0000744879, Validation Loss: 0.0173497871\n",
      "Epoch [4620/10000], Training Loss: 0.0000737496, Validation Loss: 0.0173383374\n",
      "Epoch [4640/10000], Training Loss: 0.0000730838, Validation Loss: 0.0173228197\n",
      "Epoch [4660/10000], Training Loss: 0.0001181378, Validation Loss: 0.0172389708\n",
      "Epoch [4680/10000], Training Loss: 0.0000727717, Validation Loss: 0.0171952918\n",
      "Epoch [4700/10000], Training Loss: 0.0000718150, Validation Loss: 0.0172282513\n",
      "Epoch [4720/10000], Training Loss: 0.0000703426, Validation Loss: 0.0172220953\n",
      "Epoch [4740/10000], Training Loss: 0.0000696604, Validation Loss: 0.0172143299\n",
      "Epoch [4760/10000], Training Loss: 0.0000690143, Validation Loss: 0.0172074046\n",
      "Epoch [4780/10000], Training Loss: 0.0000816745, Validation Loss: 0.0172752533\n",
      "Epoch [4800/10000], Training Loss: 0.0000700231, Validation Loss: 0.0171480961\n",
      "Epoch [4820/10000], Training Loss: 0.0000681998, Validation Loss: 0.0171492510\n",
      "Epoch [4840/10000], Training Loss: 0.0000760565, Validation Loss: 0.0171213597\n",
      "Epoch [4860/10000], Training Loss: 0.0000674262, Validation Loss: 0.0171058364\n",
      "Epoch [4880/10000], Training Loss: 0.0000656731, Validation Loss: 0.0170919094\n",
      "Epoch [4900/10000], Training Loss: 0.0000647825, Validation Loss: 0.0170848239\n",
      "Epoch [4920/10000], Training Loss: 0.0001052771, Validation Loss: 0.0169816073\n",
      "Epoch [4940/10000], Training Loss: 0.0000643997, Validation Loss: 0.0169734359\n",
      "Epoch [4960/10000], Training Loss: 0.0000633435, Validation Loss: 0.0170142408\n",
      "Epoch [4980/10000], Training Loss: 0.0000623649, Validation Loss: 0.0170191284\n",
      "Epoch [5000/10000], Training Loss: 0.0000617298, Validation Loss: 0.0170082301\n",
      "Epoch [5020/10000], Training Loss: 0.0000620026, Validation Loss: 0.0169783160\n",
      "Epoch [5040/10000], Training Loss: 0.0000794710, Validation Loss: 0.0169220325\n",
      "Epoch [5060/10000], Training Loss: 0.0000624089, Validation Loss: 0.0168942995\n",
      "Epoch [5080/10000], Training Loss: 0.0000597679, Validation Loss: 0.0169465560\n",
      "Epoch [5100/10000], Training Loss: 0.0000589866, Validation Loss: 0.0169383697\n",
      "Epoch [5120/10000], Training Loss: 0.0000598662, Validation Loss: 0.0169540253\n",
      "Epoch [5140/10000], Training Loss: 0.0000705148, Validation Loss: 0.0167912915\n",
      "Epoch [5160/10000], Training Loss: 0.0000584976, Validation Loss: 0.0168269854\n",
      "Epoch [5180/10000], Training Loss: 0.0000569792, Validation Loss: 0.0168628544\n",
      "Epoch [5200/10000], Training Loss: 0.0000564399, Validation Loss: 0.0168616138\n",
      "Epoch [5220/10000], Training Loss: 0.0000559028, Validation Loss: 0.0168636646\n",
      "Epoch [5240/10000], Training Loss: 0.0000559122, Validation Loss: 0.0168724153\n",
      "Epoch [5260/10000], Training Loss: 0.0000557489, Validation Loss: 0.0167236216\n",
      "Epoch [5280/10000], Training Loss: 0.0000561810, Validation Loss: 0.0167429093\n",
      "Epoch [5300/10000], Training Loss: 0.0000542518, Validation Loss: 0.0167883728\n",
      "Epoch [5320/10000], Training Loss: 0.0000535493, Validation Loss: 0.0167891365\n",
      "Epoch [5340/10000], Training Loss: 0.0000530092, Validation Loss: 0.0167848114\n",
      "Epoch [5360/10000], Training Loss: 0.0000526115, Validation Loss: 0.0167776253\n",
      "Epoch [5380/10000], Training Loss: 0.0000576646, Validation Loss: 0.0167644285\n",
      "Epoch [5400/10000], Training Loss: 0.0000535158, Validation Loss: 0.0167460758\n",
      "Epoch [5420/10000], Training Loss: 0.0000514862, Validation Loss: 0.0167145208\n",
      "Epoch [5440/10000], Training Loss: 0.0000512397, Validation Loss: 0.0167469438\n",
      "Epoch [5460/10000], Training Loss: 0.0000516425, Validation Loss: 0.0166286919\n",
      "Epoch [5480/10000], Training Loss: 0.0000518059, Validation Loss: 0.0166181587\n",
      "Epoch [5500/10000], Training Loss: 0.0000498986, Validation Loss: 0.0166663807\n",
      "Epoch [5520/10000], Training Loss: 0.0000490808, Validation Loss: 0.0166801717\n",
      "Epoch [5540/10000], Training Loss: 0.0000486128, Validation Loss: 0.0166877750\n",
      "Epoch [5560/10000], Training Loss: 0.0000483844, Validation Loss: 0.0166991483\n",
      "Epoch [5580/10000], Training Loss: 0.0000777245, Validation Loss: 0.0166284852\n",
      "Epoch [5600/10000], Training Loss: 0.0000513512, Validation Loss: 0.0165374670\n",
      "Epoch [5620/10000], Training Loss: 0.0000470221, Validation Loss: 0.0166131128\n",
      "Epoch [5640/10000], Training Loss: 0.0000465992, Validation Loss: 0.0166233387\n",
      "Epoch [5660/10000], Training Loss: 0.0000461891, Validation Loss: 0.0166252814\n",
      "Epoch [5680/10000], Training Loss: 0.0000457891, Validation Loss: 0.0166297033\n",
      "Epoch [5700/10000], Training Loss: 0.0000456758, Validation Loss: 0.0166435204\n",
      "Epoch [5720/10000], Training Loss: 0.0000754078, Validation Loss: 0.0163760912\n",
      "Epoch [5740/10000], Training Loss: 0.0000467002, Validation Loss: 0.0165352765\n",
      "Epoch [5760/10000], Training Loss: 0.0000445114, Validation Loss: 0.0165810883\n",
      "Epoch [5780/10000], Training Loss: 0.0000440572, Validation Loss: 0.0165715143\n",
      "Epoch [5800/10000], Training Loss: 0.0000470731, Validation Loss: 0.0165419467\n",
      "Epoch [5820/10000], Training Loss: 0.0000537198, Validation Loss: 0.0165369082\n",
      "Epoch [5840/10000], Training Loss: 0.0000439870, Validation Loss: 0.0165343322\n",
      "Epoch [5860/10000], Training Loss: 0.0000426951, Validation Loss: 0.0165461544\n",
      "Epoch [5880/10000], Training Loss: 0.0000421872, Validation Loss: 0.0165404044\n",
      "Epoch [5900/10000], Training Loss: 0.0000423134, Validation Loss: 0.0165348127\n",
      "Epoch [5920/10000], Training Loss: 0.0000470347, Validation Loss: 0.0164311882\n",
      "Epoch [5940/10000], Training Loss: 0.0000428888, Validation Loss: 0.0164812747\n",
      "Epoch [5960/10000], Training Loss: 0.0000410495, Validation Loss: 0.0165112205\n",
      "Epoch [5980/10000], Training Loss: 0.0000404350, Validation Loss: 0.0165066645\n",
      "Epoch [6000/10000], Training Loss: 0.0000400839, Validation Loss: 0.0165132955\n",
      "Epoch [6020/10000], Training Loss: 0.0000398253, Validation Loss: 0.0165097956\n",
      "Epoch [6040/10000], Training Loss: 0.0001060362, Validation Loss: 0.0163477287\n",
      "Epoch [6060/10000], Training Loss: 0.0000435016, Validation Loss: 0.0164176282\n",
      "Epoch [6080/10000], Training Loss: 0.0000392845, Validation Loss: 0.0164104551\n",
      "Epoch [6100/10000], Training Loss: 0.0000385294, Validation Loss: 0.0164521616\n",
      "Epoch [6120/10000], Training Loss: 0.0000381894, Validation Loss: 0.0164667834\n",
      "Epoch [6140/10000], Training Loss: 0.0000378728, Validation Loss: 0.0164714567\n",
      "Epoch [6160/10000], Training Loss: 0.0000375608, Validation Loss: 0.0164772794\n",
      "Epoch [6180/10000], Training Loss: 0.0000375352, Validation Loss: 0.0164706316\n",
      "Epoch [6200/10000], Training Loss: 0.0000601920, Validation Loss: 0.0165333003\n",
      "Epoch [6220/10000], Training Loss: 0.0000374262, Validation Loss: 0.0164553523\n",
      "Epoch [6240/10000], Training Loss: 0.0000368042, Validation Loss: 0.0164299756\n",
      "Epoch [6260/10000], Training Loss: 0.0000361435, Validation Loss: 0.0164375007\n",
      "Epoch [6280/10000], Training Loss: 0.0000361198, Validation Loss: 0.0164392795\n",
      "Epoch [6300/10000], Training Loss: 0.0000480923, Validation Loss: 0.0163247678\n",
      "Epoch [6320/10000], Training Loss: 0.0000370462, Validation Loss: 0.0163978171\n",
      "Epoch [6340/10000], Training Loss: 0.0000354823, Validation Loss: 0.0164140593\n",
      "Epoch [6360/10000], Training Loss: 0.0000347631, Validation Loss: 0.0164208598\n",
      "Epoch [6380/10000], Training Loss: 0.0000344361, Validation Loss: 0.0164252818\n",
      "Epoch [6400/10000], Training Loss: 0.0000341599, Validation Loss: 0.0164329112\n",
      "Epoch [6420/10000], Training Loss: 0.0000535374, Validation Loss: 0.0163156781\n",
      "Epoch [6440/10000], Training Loss: 0.0000434555, Validation Loss: 0.0162540078\n",
      "Epoch [6460/10000], Training Loss: 0.0000341251, Validation Loss: 0.0163881946\n",
      "Epoch [6480/10000], Training Loss: 0.0000332103, Validation Loss: 0.0163880568\n",
      "Epoch [6500/10000], Training Loss: 0.0000328446, Validation Loss: 0.0163956042\n",
      "Epoch [6520/10000], Training Loss: 0.0000325848, Validation Loss: 0.0164098851\n",
      "Epoch [6540/10000], Training Loss: 0.0000323231, Validation Loss: 0.0164178815\n",
      "Epoch [6560/10000], Training Loss: 0.0000321508, Validation Loss: 0.0164175630\n",
      "Epoch [6580/10000], Training Loss: 0.0000903466, Validation Loss: 0.0162302852\n",
      "Epoch [6600/10000], Training Loss: 0.0000376124, Validation Loss: 0.0162731726\n",
      "Epoch [6620/10000], Training Loss: 0.0000321705, Validation Loss: 0.0163474251\n",
      "Epoch [6640/10000], Training Loss: 0.0000311508, Validation Loss: 0.0163807459\n",
      "Epoch [6660/10000], Training Loss: 0.0000308820, Validation Loss: 0.0163916461\n",
      "Epoch [6680/10000], Training Loss: 0.0000306243, Validation Loss: 0.0163993277\n",
      "Epoch [6700/10000], Training Loss: 0.0000303845, Validation Loss: 0.0164081044\n",
      "Epoch [6720/10000], Training Loss: 0.0000337774, Validation Loss: 0.0163280182\n",
      "Epoch [6740/10000], Training Loss: 0.0000341798, Validation Loss: 0.0161975399\n",
      "Epoch [6760/10000], Training Loss: 0.0000311589, Validation Loss: 0.0163889080\n",
      "Epoch [6780/10000], Training Loss: 0.0000296041, Validation Loss: 0.0163796544\n",
      "Epoch [6800/10000], Training Loss: 0.0000293544, Validation Loss: 0.0163824968\n",
      "Epoch [6820/10000], Training Loss: 0.0000722675, Validation Loss: 0.0162258390\n",
      "Epoch [6840/10000], Training Loss: 0.0000322332, Validation Loss: 0.0162580963\n",
      "Epoch [6860/10000], Training Loss: 0.0000286257, Validation Loss: 0.0163521804\n",
      "Epoch [6880/10000], Training Loss: 0.0000284310, Validation Loss: 0.0163706504\n",
      "Epoch [6900/10000], Training Loss: 0.0000281706, Validation Loss: 0.0163812321\n",
      "Epoch [6920/10000], Training Loss: 0.0000279735, Validation Loss: 0.0163929407\n",
      "Epoch [6940/10000], Training Loss: 0.0000391115, Validation Loss: 0.0163027197\n",
      "Epoch [6960/10000], Training Loss: 0.0000311350, Validation Loss: 0.0162301101\n",
      "Epoch [6980/10000], Training Loss: 0.0000280077, Validation Loss: 0.0163051393\n",
      "Epoch [7000/10000], Training Loss: 0.0000272214, Validation Loss: 0.0163733773\n",
      "Epoch [7020/10000], Training Loss: 0.0000269447, Validation Loss: 0.0163792372\n",
      "Epoch [7040/10000], Training Loss: 0.0000267290, Validation Loss: 0.0163888335\n",
      "Epoch [7060/10000], Training Loss: 0.0000265204, Validation Loss: 0.0164038762\n",
      "Epoch [7080/10000], Training Loss: 0.0000264430, Validation Loss: 0.0164284837\n",
      "Epoch [7100/10000], Training Loss: 0.0000423177, Validation Loss: 0.0161879957\n",
      "Epoch [7120/10000], Training Loss: 0.0000279476, Validation Loss: 0.0162499156\n",
      "Epoch [7140/10000], Training Loss: 0.0000265537, Validation Loss: 0.0163531061\n",
      "Epoch [7160/10000], Training Loss: 0.0000256772, Validation Loss: 0.0163479466\n",
      "Epoch [7180/10000], Training Loss: 0.0000253938, Validation Loss: 0.0163750779\n",
      "Epoch [7200/10000], Training Loss: 0.0000251991, Validation Loss: 0.0163884051\n",
      "Epoch [7220/10000], Training Loss: 0.0000250091, Validation Loss: 0.0164042972\n",
      "Epoch [7240/10000], Training Loss: 0.0000248213, Validation Loss: 0.0164173525\n",
      "Epoch [7260/10000], Training Loss: 0.0000250008, Validation Loss: 0.0163955316\n",
      "Epoch [7280/10000], Training Loss: 0.0000413555, Validation Loss: 0.0164028164\n",
      "Epoch [7300/10000], Training Loss: 0.0000271828, Validation Loss: 0.0163920186\n",
      "Epoch [7320/10000], Training Loss: 0.0000244442, Validation Loss: 0.0163864605\n",
      "Epoch [7340/10000], Training Loss: 0.0000239904, Validation Loss: 0.0163815059\n",
      "Epoch [7360/10000], Training Loss: 0.0000237885, Validation Loss: 0.0163918417\n",
      "Epoch [7380/10000], Training Loss: 0.0000244214, Validation Loss: 0.0164302420\n",
      "Epoch [7400/10000], Training Loss: 0.0000325444, Validation Loss: 0.0161881000\n",
      "Epoch [7420/10000], Training Loss: 0.0000244058, Validation Loss: 0.0163128972\n",
      "Epoch [7440/10000], Training Loss: 0.0000232852, Validation Loss: 0.0163779929\n",
      "Epoch [7460/10000], Training Loss: 0.0000229697, Validation Loss: 0.0163881741\n",
      "Epoch [7480/10000], Training Loss: 0.0000227853, Validation Loss: 0.0164027680\n",
      "Epoch [7500/10000], Training Loss: 0.0000226108, Validation Loss: 0.0164219234\n",
      "Epoch [7520/10000], Training Loss: 0.0000228324, Validation Loss: 0.0164542384\n",
      "Epoch [7540/10000], Training Loss: 0.0000288650, Validation Loss: 0.0161801111\n",
      "Epoch [7560/10000], Training Loss: 0.0000233631, Validation Loss: 0.0163204521\n",
      "Epoch [7580/10000], Training Loss: 0.0000220709, Validation Loss: 0.0163631551\n",
      "Epoch [7600/10000], Training Loss: 0.0000219038, Validation Loss: 0.0163781606\n",
      "Epoch [7620/10000], Training Loss: 0.0000216873, Validation Loss: 0.0164092258\n",
      "Epoch [7640/10000], Training Loss: 0.0000215251, Validation Loss: 0.0164246336\n",
      "Epoch [7660/10000], Training Loss: 0.0000213685, Validation Loss: 0.0164422244\n",
      "Epoch [7680/10000], Training Loss: 0.0000212235, Validation Loss: 0.0164597016\n",
      "Epoch [7700/10000], Training Loss: 0.0000439267, Validation Loss: 0.0166509114\n",
      "Epoch [7720/10000], Training Loss: 0.0000281749, Validation Loss: 0.0162206292\n",
      "Epoch [7740/10000], Training Loss: 0.0000219035, Validation Loss: 0.0163877811\n",
      "Epoch [7760/10000], Training Loss: 0.0000207791, Validation Loss: 0.0163853411\n",
      "Epoch [7780/10000], Training Loss: 0.0000205275, Validation Loss: 0.0164223760\n",
      "Epoch [7800/10000], Training Loss: 0.0000203618, Validation Loss: 0.0164338965\n",
      "Epoch [7820/10000], Training Loss: 0.0000202137, Validation Loss: 0.0164508410\n",
      "Epoch [7840/10000], Training Loss: 0.0000200692, Validation Loss: 0.0164662767\n",
      "Epoch [7860/10000], Training Loss: 0.0000199270, Validation Loss: 0.0164784994\n",
      "Epoch [7880/10000], Training Loss: 0.0000339637, Validation Loss: 0.0162433721\n",
      "Epoch [7900/10000], Training Loss: 0.0000396780, Validation Loss: 0.0163186435\n",
      "Epoch [7920/10000], Training Loss: 0.0000219826, Validation Loss: 0.0162407570\n",
      "Epoch [7940/10000], Training Loss: 0.0000195154, Validation Loss: 0.0163862500\n",
      "Epoch [7960/10000], Training Loss: 0.0000193359, Validation Loss: 0.0163991209\n",
      "Epoch [7980/10000], Training Loss: 0.0000191607, Validation Loss: 0.0164135192\n",
      "Epoch [8000/10000], Training Loss: 0.0000190261, Validation Loss: 0.0164341964\n",
      "Epoch [8020/10000], Training Loss: 0.0000188939, Validation Loss: 0.0164521895\n",
      "Epoch [8040/10000], Training Loss: 0.0000187628, Validation Loss: 0.0164674558\n",
      "Epoch [8060/10000], Training Loss: 0.0000186327, Validation Loss: 0.0164811779\n",
      "Epoch [8080/10000], Training Loss: 0.0000196365, Validation Loss: 0.0165323131\n",
      "Epoch [8100/10000], Training Loss: 0.0000219990, Validation Loss: 0.0163000580\n",
      "Epoch [8120/10000], Training Loss: 0.0000186097, Validation Loss: 0.0163100865\n",
      "Epoch [8140/10000], Training Loss: 0.0000183096, Validation Loss: 0.0163553376\n",
      "Epoch [8160/10000], Training Loss: 0.0000181319, Validation Loss: 0.0163768288\n",
      "Epoch [8180/10000], Training Loss: 0.0000179422, Validation Loss: 0.0164129306\n",
      "Epoch [8200/10000], Training Loss: 0.0000178157, Validation Loss: 0.0164338481\n",
      "Epoch [8220/10000], Training Loss: 0.0000176940, Validation Loss: 0.0164526533\n",
      "Epoch [8240/10000], Training Loss: 0.0000175740, Validation Loss: 0.0164676998\n",
      "Epoch [8260/10000], Training Loss: 0.0000174548, Validation Loss: 0.0164814238\n",
      "Epoch [8280/10000], Training Loss: 0.0000173362, Validation Loss: 0.0164939985\n",
      "Epoch [8300/10000], Training Loss: 0.0000172181, Validation Loss: 0.0165058821\n",
      "Epoch [8320/10000], Training Loss: 0.0000171008, Validation Loss: 0.0165177137\n",
      "Epoch [8340/10000], Training Loss: 0.0000203275, Validation Loss: 0.0166192204\n",
      "Epoch [8360/10000], Training Loss: 0.0000396640, Validation Loss: 0.0162007287\n",
      "Epoch [8380/10000], Training Loss: 0.0000190944, Validation Loss: 0.0162586402\n",
      "Epoch [8400/10000], Training Loss: 0.0000170145, Validation Loss: 0.0163486470\n",
      "Epoch [8420/10000], Training Loss: 0.0000166015, Validation Loss: 0.0163973961\n",
      "Epoch [8440/10000], Training Loss: 0.0000164808, Validation Loss: 0.0164362174\n",
      "Epoch [8460/10000], Training Loss: 0.0000163644, Validation Loss: 0.0164565705\n",
      "Epoch [8480/10000], Training Loss: 0.0000162549, Validation Loss: 0.0164731070\n",
      "Epoch [8500/10000], Training Loss: 0.0000161464, Validation Loss: 0.0164885856\n",
      "Epoch [8520/10000], Training Loss: 0.0000160386, Validation Loss: 0.0165019352\n",
      "Epoch [8540/10000], Training Loss: 0.0000159315, Validation Loss: 0.0165136885\n",
      "Epoch [8560/10000], Training Loss: 0.0000170156, Validation Loss: 0.0164842084\n",
      "Epoch [8580/10000], Training Loss: 0.0000350875, Validation Loss: 0.0162358228\n",
      "Epoch [8600/10000], Training Loss: 0.0000167991, Validation Loss: 0.0163871944\n",
      "Epoch [8620/10000], Training Loss: 0.0000159195, Validation Loss: 0.0164358392\n",
      "Epoch [8640/10000], Training Loss: 0.0000154749, Validation Loss: 0.0164378975\n",
      "Epoch [8660/10000], Training Loss: 0.0000153544, Validation Loss: 0.0164609812\n",
      "Epoch [8680/10000], Training Loss: 0.0000152472, Validation Loss: 0.0164790824\n",
      "Epoch [8700/10000], Training Loss: 0.0000151464, Validation Loss: 0.0164950825\n",
      "Epoch [8720/10000], Training Loss: 0.0000150463, Validation Loss: 0.0165086035\n",
      "Epoch [8740/10000], Training Loss: 0.0000149468, Validation Loss: 0.0165210944\n",
      "Epoch [8760/10000], Training Loss: 0.0000148487, Validation Loss: 0.0165333860\n",
      "Epoch [8780/10000], Training Loss: 0.0000358141, Validation Loss: 0.0167233758\n",
      "Epoch [8800/10000], Training Loss: 0.0000224505, Validation Loss: 0.0160369277\n",
      "Epoch [8820/10000], Training Loss: 0.0000173983, Validation Loss: 0.0162388962\n",
      "Epoch [8840/10000], Training Loss: 0.0000148537, Validation Loss: 0.0163476486\n",
      "Epoch [8860/10000], Training Loss: 0.0000144638, Validation Loss: 0.0163953975\n",
      "Epoch [8880/10000], Training Loss: 0.0000143341, Validation Loss: 0.0164267216\n",
      "Epoch [8900/10000], Training Loss: 0.0000142388, Validation Loss: 0.0164504200\n",
      "Epoch [8920/10000], Training Loss: 0.0000141458, Validation Loss: 0.0164658707\n",
      "Epoch [8940/10000], Training Loss: 0.0000140542, Validation Loss: 0.0164805558\n",
      "Epoch [8960/10000], Training Loss: 0.0000139632, Validation Loss: 0.0164931975\n",
      "Epoch [8980/10000], Training Loss: 0.0000138726, Validation Loss: 0.0165047497\n",
      "Epoch [9000/10000], Training Loss: 0.0000138265, Validation Loss: 0.0165257286\n",
      "Epoch [9020/10000], Training Loss: 0.0000179432, Validation Loss: 0.0162676144\n",
      "Epoch [9040/10000], Training Loss: 0.0000165646, Validation Loss: 0.0164980218\n",
      "Epoch [9060/10000], Training Loss: 0.0000135910, Validation Loss: 0.0164985247\n",
      "Epoch [9080/10000], Training Loss: 0.0000136983, Validation Loss: 0.0164934974\n",
      "Epoch [9100/10000], Training Loss: 0.0000371285, Validation Loss: 0.0166874733\n",
      "Epoch [9120/10000], Training Loss: 0.0000150035, Validation Loss: 0.0164799578\n",
      "Epoch [9140/10000], Training Loss: 0.0000133884, Validation Loss: 0.0164640285\n",
      "Epoch [9160/10000], Training Loss: 0.0000131504, Validation Loss: 0.0164873824\n",
      "Epoch [9180/10000], Training Loss: 0.0000132736, Validation Loss: 0.0164835975\n",
      "Epoch [9200/10000], Training Loss: 0.0000546171, Validation Loss: 0.0162835009\n",
      "Epoch [9220/10000], Training Loss: 0.0000139217, Validation Loss: 0.0163928550\n",
      "Epoch [9240/10000], Training Loss: 0.0000129512, Validation Loss: 0.0164631438\n",
      "Epoch [9260/10000], Training Loss: 0.0000127310, Validation Loss: 0.0164710693\n",
      "Epoch [9280/10000], Training Loss: 0.0000126642, Validation Loss: 0.0164820142\n",
      "Epoch [9300/10000], Training Loss: 0.0000125678, Validation Loss: 0.0164995585\n",
      "Epoch [9320/10000], Training Loss: 0.0000130652, Validation Loss: 0.0164793227\n",
      "Epoch [9340/10000], Training Loss: 0.0000296943, Validation Loss: 0.0164979342\n",
      "Epoch [9360/10000], Training Loss: 0.0000138394, Validation Loss: 0.0163528342\n",
      "Epoch [9380/10000], Training Loss: 0.0000123314, Validation Loss: 0.0163925998\n",
      "Epoch [9400/10000], Training Loss: 0.0000122297, Validation Loss: 0.0164378677\n",
      "Epoch [9420/10000], Training Loss: 0.0000121343, Validation Loss: 0.0164585765\n",
      "Epoch [9440/10000], Training Loss: 0.0000120520, Validation Loss: 0.0164735224\n",
      "Epoch [9460/10000], Training Loss: 0.0000119754, Validation Loss: 0.0164871812\n",
      "Epoch [9480/10000], Training Loss: 0.0000118997, Validation Loss: 0.0164985862\n",
      "Epoch [9500/10000], Training Loss: 0.0000118331, Validation Loss: 0.0165061597\n",
      "Epoch [9520/10000], Training Loss: 0.0001154039, Validation Loss: 0.0161819085\n",
      "Epoch [9540/10000], Training Loss: 0.0000156344, Validation Loss: 0.0162709095\n",
      "Epoch [9560/10000], Training Loss: 0.0000127467, Validation Loss: 0.0163482819\n",
      "Epoch [9580/10000], Training Loss: 0.0000117557, Validation Loss: 0.0163838789\n",
      "Epoch [9600/10000], Training Loss: 0.0000115168, Validation Loss: 0.0164089873\n",
      "Epoch [9620/10000], Training Loss: 0.0000114351, Validation Loss: 0.0164347012\n",
      "Epoch [9640/10000], Training Loss: 0.0000113617, Validation Loss: 0.0164535455\n",
      "Epoch [9660/10000], Training Loss: 0.0000112910, Validation Loss: 0.0164681822\n",
      "Epoch [9680/10000], Training Loss: 0.0000112212, Validation Loss: 0.0164804738\n",
      "Epoch [9700/10000], Training Loss: 0.0000111935, Validation Loss: 0.0165102258\n",
      "Epoch [9720/10000], Training Loss: 0.0000154681, Validation Loss: 0.0161672030\n",
      "Epoch [9740/10000], Training Loss: 0.0000125948, Validation Loss: 0.0163990371\n",
      "Epoch [9760/10000], Training Loss: 0.0000111286, Validation Loss: 0.0164379049\n",
      "Epoch [9780/10000], Training Loss: 0.0000110427, Validation Loss: 0.0164031778\n",
      "Epoch [9800/10000], Training Loss: 0.0000490623, Validation Loss: 0.0163430758\n",
      "Epoch [9820/10000], Training Loss: 0.0000156814, Validation Loss: 0.0163009148\n",
      "Epoch [9840/10000], Training Loss: 0.0000108018, Validation Loss: 0.0163785927\n",
      "Epoch [9860/10000], Training Loss: 0.0000106766, Validation Loss: 0.0164074954\n",
      "Epoch [9880/10000], Training Loss: 0.0000106089, Validation Loss: 0.0164208449\n",
      "Epoch [9900/10000], Training Loss: 0.0000105282, Validation Loss: 0.0164383613\n",
      "Epoch [9920/10000], Training Loss: 0.0000104962, Validation Loss: 0.0164558068\n",
      "Epoch [9940/10000], Training Loss: 0.0000948065, Validation Loss: 0.0166741684\n",
      "Epoch [9960/10000], Training Loss: 0.0000196028, Validation Loss: 0.0161943268\n",
      "Epoch [9980/10000], Training Loss: 0.0000108195, Validation Loss: 0.0163271483\n",
      "Epoch [10000/10000], Training Loss: 0.0000102850, Validation Loss: 0.0163569972\n",
      "Training finished!\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "# Initialize model\n",
    "input_size = x_train.shape[2]\n",
    "hidden_size = 32\n",
    "num_layers = 1\n",
    "output_size = 12\n",
    "model = LSTMModel(input_size, hidden_size, num_layers, output_size)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0003)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10000\n",
    "batch_size = x_train.shape[0]\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(0, 1):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        batch_data = x_train[i:i + batch_size]\n",
    "        batch_labels = y_train[i:i + batch_size]\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(x_train, lengths)\n",
    "        loss = criterion(outputs, y_train)\n",
    "\n",
    "        # Backpropagation and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(x_validation, lengths_val)\n",
    "            val_loss = criterion(val_outputs, y_validation)\n",
    "    \n",
    "    \n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {loss.item():.10f}, Validation Loss: {val_loss.item():.10f}')\n",
    "\n",
    "print(\"Training finished!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T19:59:57.947626004Z",
     "start_time": "2023-08-29T19:59:35.204168033Z"
    }
   },
   "id": "9e80e28b10534d0"
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Mean Squared Error: 1.7848064651091893\n"
     ]
    }
   ],
   "source": [
    "val_outputs = model(x_validation, lengths_val)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def calculae_amse_tensor(y_pred, y_validation_df):\n",
    "    mse_values = []  # To store MSE values for each column\n",
    "\n",
    "    # calculate average MSE for each column of numpy array of y_pred and y_validation_df\n",
    "    for i in range(y_pred.shape[1]):\n",
    "        mse = mean_squared_error(y_validation_df[:, i], y_pred[:, i])\n",
    "        mse_values.append(mse)\n",
    "\n",
    "    # Calculate the mean of MSE values for all columns\n",
    "    average_mse = sum(mse_values) / len(mse_values)\n",
    "\n",
    "    print(f\"Average Mean Squared Error: {average_mse}\")\n",
    "\n",
    "val_outputs = val_outputs.detach().numpy()\n",
    "y_validation = y_validation.detach().numpy()\n",
    "\n",
    "calculae_amse_tensor(val_outputs, y_validation)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T21:42:58.065908626Z",
     "start_time": "2023-08-28T21:42:58.020010858Z"
    }
   },
   "id": "14cbc2628a5f9923"
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/10000], Training Loss: 1.0748441219, Validation Loss: 0.6202629805\n",
      "Epoch [40/10000], Training Loss: 0.9206137657, Validation Loss: 0.5179287791\n",
      "Epoch [60/10000], Training Loss: 0.7670961618, Validation Loss: 0.4235973954\n",
      "Epoch [80/10000], Training Loss: 0.6291338205, Validation Loss: 0.3464701772\n",
      "Epoch [100/10000], Training Loss: 0.5192005038, Validation Loss: 0.2873368561\n",
      "Epoch [120/10000], Training Loss: 0.4379957616, Validation Loss: 0.2430446297\n",
      "Epoch [140/10000], Training Loss: 0.3753544390, Validation Loss: 0.2080564946\n",
      "Epoch [160/10000], Training Loss: 0.3238978088, Validation Loss: 0.1769459546\n",
      "Epoch [180/10000], Training Loss: 0.2765240967, Validation Loss: 0.1520048231\n",
      "Epoch [200/10000], Training Loss: 0.2351768315, Validation Loss: 0.1328781992\n",
      "Epoch [220/10000], Training Loss: 0.2051547021, Validation Loss: 0.1181939691\n",
      "Epoch [240/10000], Training Loss: 0.1808957607, Validation Loss: 0.1070468277\n",
      "Epoch [260/10000], Training Loss: 0.1598491669, Validation Loss: 0.0980568230\n",
      "Epoch [280/10000], Training Loss: 0.1426835209, Validation Loss: 0.0900564045\n",
      "Epoch [300/10000], Training Loss: 0.1296523660, Validation Loss: 0.0826765820\n",
      "Epoch [320/10000], Training Loss: 0.1190970913, Validation Loss: 0.0759344548\n",
      "Epoch [340/10000], Training Loss: 0.1100921035, Validation Loss: 0.0698745921\n",
      "Epoch [360/10000], Training Loss: 0.1021692082, Validation Loss: 0.0645347908\n",
      "Epoch [380/10000], Training Loss: 0.0950326324, Validation Loss: 0.0598008446\n",
      "Epoch [400/10000], Training Loss: 0.0885916799, Validation Loss: 0.0555425324\n",
      "Epoch [420/10000], Training Loss: 0.0828319713, Validation Loss: 0.0516076498\n",
      "Epoch [440/10000], Training Loss: 0.0776747763, Validation Loss: 0.0479347706\n",
      "Epoch [460/10000], Training Loss: 0.0729994625, Validation Loss: 0.0445548259\n",
      "Epoch [480/10000], Training Loss: 0.0686952770, Validation Loss: 0.0416256152\n",
      "Epoch [500/10000], Training Loss: 0.0646849796, Validation Loss: 0.0393759198\n",
      "Epoch [520/10000], Training Loss: 0.0609515384, Validation Loss: 0.0374799371\n",
      "Epoch [540/10000], Training Loss: 0.0575026236, Validation Loss: 0.0355863310\n",
      "Epoch [560/10000], Training Loss: 0.0543259345, Validation Loss: 0.0338709839\n",
      "Epoch [580/10000], Training Loss: 0.0513977744, Validation Loss: 0.0323291644\n",
      "Epoch [600/10000], Training Loss: 0.0486913957, Validation Loss: 0.0309477728\n",
      "Epoch [620/10000], Training Loss: 0.0461820550, Validation Loss: 0.0297029056\n",
      "Epoch [640/10000], Training Loss: 0.0438488387, Validation Loss: 0.0285720844\n",
      "Epoch [660/10000], Training Loss: 0.0416742302, Validation Loss: 0.0275362413\n",
      "Epoch [680/10000], Training Loss: 0.0396428555, Validation Loss: 0.0265804827\n",
      "Epoch [700/10000], Training Loss: 0.0377410874, Validation Loss: 0.0256950036\n",
      "Epoch [720/10000], Training Loss: 0.0359571017, Validation Loss: 0.0248737521\n",
      "Epoch [740/10000], Training Loss: 0.0342815444, Validation Loss: 0.0241123717\n",
      "Epoch [760/10000], Training Loss: 0.0327076279, Validation Loss: 0.0234054197\n",
      "Epoch [780/10000], Training Loss: 0.0312291048, Validation Loss: 0.0227450058\n",
      "Epoch [800/10000], Training Loss: 0.0298380796, Validation Loss: 0.0221246183\n",
      "Epoch [820/10000], Training Loss: 0.0285263173, Validation Loss: 0.0215424858\n",
      "Epoch [840/10000], Training Loss: 0.0272866469, Validation Loss: 0.0209988710\n",
      "Epoch [860/10000], Training Loss: 0.0261128973, Validation Loss: 0.0204934981\n",
      "Epoch [880/10000], Training Loss: 0.0249996893, Validation Loss: 0.0200251807\n",
      "Epoch [900/10000], Training Loss: 0.0239426289, Validation Loss: 0.0195921697\n",
      "Epoch [920/10000], Training Loss: 0.0229385179, Validation Loss: 0.0191927962\n",
      "Epoch [940/10000], Training Loss: 0.0219849963, Validation Loss: 0.0188255776\n",
      "Epoch [960/10000], Training Loss: 0.0210792497, Validation Loss: 0.0184883494\n",
      "Epoch [980/10000], Training Loss: 0.0202177633, Validation Loss: 0.0181767568\n",
      "Epoch [1000/10000], Training Loss: 0.0193975978, Validation Loss: 0.0178841967\n",
      "Epoch [1020/10000], Training Loss: 0.0186163187, Validation Loss: 0.0176043902\n",
      "Epoch [1040/10000], Training Loss: 0.0178712439, Validation Loss: 0.0173331741\n",
      "Epoch [1060/10000], Training Loss: 0.0171594173, Validation Loss: 0.0170692857\n",
      "Epoch [1080/10000], Training Loss: 0.0164785814, Validation Loss: 0.0168177728\n",
      "Epoch [1100/10000], Training Loss: 0.0158282965, Validation Loss: 0.0165852290\n",
      "Epoch [1120/10000], Training Loss: 0.0152080208, Validation Loss: 0.0163693484\n",
      "Epoch [1140/10000], Training Loss: 0.0146167455, Validation Loss: 0.0161679368\n",
      "Epoch [1160/10000], Training Loss: 0.0140532535, Validation Loss: 0.0159804001\n",
      "Epoch [1180/10000], Training Loss: 0.0135162277, Validation Loss: 0.0158050153\n",
      "Epoch [1200/10000], Training Loss: 0.0130043253, Validation Loss: 0.0156400707\n",
      "Epoch [1220/10000], Training Loss: 0.0125162406, Validation Loss: 0.0154837593\n",
      "Epoch [1240/10000], Training Loss: 0.0120506985, Validation Loss: 0.0153344208\n",
      "Epoch [1260/10000], Training Loss: 0.0116064800, Validation Loss: 0.0151907988\n",
      "Epoch [1280/10000], Training Loss: 0.0111824404, Validation Loss: 0.0150519917\n",
      "Epoch [1300/10000], Training Loss: 0.0107774762, Validation Loss: 0.0149173988\n",
      "Epoch [1320/10000], Training Loss: 0.0103905769, Validation Loss: 0.0147866467\n",
      "Epoch [1340/10000], Training Loss: 0.0100207692, Validation Loss: 0.0146594755\n",
      "Epoch [1360/10000], Training Loss: 0.0096671712, Validation Loss: 0.0145357121\n",
      "Epoch [1380/10000], Training Loss: 0.0093289418, Validation Loss: 0.0144152259\n",
      "Epoch [1400/10000], Training Loss: 0.0090053063, Validation Loss: 0.0142979054\n",
      "Epoch [1420/10000], Training Loss: 0.0086955344, Validation Loss: 0.0141836703\n",
      "Epoch [1440/10000], Training Loss: 0.0083989361, Validation Loss: 0.0140724350\n",
      "Epoch [1460/10000], Training Loss: 0.0081148539, Validation Loss: 0.0139641427\n",
      "Epoch [1480/10000], Training Loss: 0.0078426618, Validation Loss: 0.0138587188\n",
      "Epoch [1500/10000], Training Loss: 0.0075817662, Validation Loss: 0.0137560889\n",
      "Epoch [1520/10000], Training Loss: 0.0073315916, Validation Loss: 0.0136561571\n",
      "Epoch [1540/10000], Training Loss: 0.0070916042, Validation Loss: 0.0135588208\n",
      "Epoch [1560/10000], Training Loss: 0.0068612928, Validation Loss: 0.0134639591\n",
      "Epoch [1580/10000], Training Loss: 0.0066401819, Validation Loss: 0.0133714722\n",
      "Epoch [1600/10000], Training Loss: 0.0064278198, Validation Loss: 0.0132812588\n",
      "Epoch [1620/10000], Training Loss: 0.0062237754, Validation Loss: 0.0131932711\n",
      "Epoch [1640/10000], Training Loss: 0.0060276529, Validation Loss: 0.0131074656\n",
      "Epoch [1660/10000], Training Loss: 0.0058390661, Validation Loss: 0.0130238328\n",
      "Epoch [1680/10000], Training Loss: 0.0056576575, Validation Loss: 0.0129423896\n",
      "Epoch [1700/10000], Training Loss: 0.0054830820, Validation Loss: 0.0128631750\n",
      "Epoch [1720/10000], Training Loss: 0.0053150193, Validation Loss: 0.0127862385\n",
      "Epoch [1740/10000], Training Loss: 0.0051531587, Validation Loss: 0.0127116535\n",
      "Epoch [1760/10000], Training Loss: 0.0049972157, Validation Loss: 0.0126395086\n",
      "Epoch [1780/10000], Training Loss: 0.0048469086, Validation Loss: 0.0125699034\n",
      "Epoch [1800/10000], Training Loss: 0.0047019748, Validation Loss: 0.0125029609\n",
      "Epoch [1820/10000], Training Loss: 0.0045621605, Validation Loss: 0.0124388114\n",
      "Epoch [1840/10000], Training Loss: 0.0044272169, Validation Loss: 0.0123776123\n",
      "Epoch [1860/10000], Training Loss: 0.0042969012, Validation Loss: 0.0123195387\n",
      "Epoch [1880/10000], Training Loss: 0.0041709775, Validation Loss: 0.0122647788\n",
      "Epoch [1900/10000], Training Loss: 0.0040492155, Validation Loss: 0.0122135039\n",
      "Epoch [1920/10000], Training Loss: 0.0039314181, Validation Loss: 0.0121658202\n",
      "Epoch [1940/10000], Training Loss: 0.0038174295, Validation Loss: 0.0121217268\n",
      "Epoch [1960/10000], Training Loss: 0.0037071544, Validation Loss: 0.0120810568\n",
      "Epoch [1980/10000], Training Loss: 0.0036005341, Validation Loss: 0.0120434873\n",
      "Epoch [2000/10000], Training Loss: 0.0034975256, Validation Loss: 0.0120085860\n",
      "Epoch [2020/10000], Training Loss: 0.0033980659, Validation Loss: 0.0119759040\n",
      "Epoch [2040/10000], Training Loss: 0.0033020664, Validation Loss: 0.0119450055\n",
      "Epoch [2060/10000], Training Loss: 0.0032094126, Validation Loss: 0.0119155813\n",
      "Epoch [2080/10000], Training Loss: 0.0031199763, Validation Loss: 0.0118873948\n",
      "Epoch [2100/10000], Training Loss: 0.0030336261, Validation Loss: 0.0118602645\n",
      "Epoch [2120/10000], Training Loss: 0.0029503244, Validation Loss: 0.0118272072\n",
      "Epoch [2140/10000], Training Loss: 0.0028698049, Validation Loss: 0.0118138185\n",
      "Epoch [2160/10000], Training Loss: 0.0027919833, Validation Loss: 0.0117868055\n",
      "Epoch [2180/10000], Training Loss: 0.0027168051, Validation Loss: 0.0117628612\n",
      "Epoch [2200/10000], Training Loss: 0.0026441170, Validation Loss: 0.0117400140\n",
      "Epoch [2220/10000], Training Loss: 0.0025738084, Validation Loss: 0.0117186913\n",
      "Epoch [2240/10000], Training Loss: 0.0025057849, Validation Loss: 0.0116979768\n",
      "Epoch [2260/10000], Training Loss: 0.0024399594, Validation Loss: 0.0116780419\n",
      "Epoch [2280/10000], Training Loss: 0.0023762432, Validation Loss: 0.0116587970\n",
      "Epoch [2300/10000], Training Loss: 0.0023145601, Validation Loss: 0.0116402376\n",
      "Epoch [2320/10000], Training Loss: 0.0022548335, Validation Loss: 0.0116218729\n",
      "Epoch [2340/10000], Training Loss: 0.0021971192, Validation Loss: 0.0116168987\n",
      "Epoch [2360/10000], Training Loss: 0.0021410733, Validation Loss: 0.0115895625\n",
      "Epoch [2380/10000], Training Loss: 0.0020868911, Validation Loss: 0.0115711307\n",
      "Epoch [2400/10000], Training Loss: 0.0020343903, Validation Loss: 0.0115566133\n",
      "Epoch [2420/10000], Training Loss: 0.0019835257, Validation Loss: 0.0115421861\n",
      "Epoch [2440/10000], Training Loss: 0.0019342346, Validation Loss: 0.0115277041\n",
      "Epoch [2460/10000], Training Loss: 0.0018864648, Validation Loss: 0.0115136039\n",
      "Epoch [2480/10000], Training Loss: 0.0018401654, Validation Loss: 0.0114998510\n",
      "Epoch [2500/10000], Training Loss: 0.0017952875, Validation Loss: 0.0114864493\n",
      "Epoch [2520/10000], Training Loss: 0.0017517933, Validation Loss: 0.0114759812\n",
      "Epoch [2540/10000], Training Loss: 0.0017098368, Validation Loss: 0.0114558339\n",
      "Epoch [2560/10000], Training Loss: 0.0016688367, Validation Loss: 0.0114437062\n",
      "Epoch [2580/10000], Training Loss: 0.0016292724, Validation Loss: 0.0114351865\n",
      "Epoch [2600/10000], Training Loss: 0.0015909038, Validation Loss: 0.0114205545\n",
      "Epoch [2620/10000], Training Loss: 0.0015536927, Validation Loss: 0.0114074983\n",
      "Epoch [2640/10000], Training Loss: 0.0015175999, Validation Loss: 0.0113946460\n",
      "Epoch [2660/10000], Training Loss: 0.0014825861, Validation Loss: 0.0113814222\n",
      "Epoch [2680/10000], Training Loss: 0.0014486180, Validation Loss: 0.0113679711\n",
      "Epoch [2700/10000], Training Loss: 0.0014156749, Validation Loss: 0.0113500915\n",
      "Epoch [2720/10000], Training Loss: 0.0013837952, Validation Loss: 0.0113248825\n",
      "Epoch [2740/10000], Training Loss: 0.0013528406, Validation Loss: 0.0113236234\n",
      "Epoch [2760/10000], Training Loss: 0.0013228511, Validation Loss: 0.0113126393\n",
      "Epoch [2780/10000], Training Loss: 0.0012937188, Validation Loss: 0.0112962704\n",
      "Epoch [2800/10000], Training Loss: 0.0012654419, Validation Loss: 0.0112804398\n",
      "Epoch [2820/10000], Training Loss: 0.0012379789, Validation Loss: 0.0112649724\n",
      "Epoch [2840/10000], Training Loss: 0.0012113020, Validation Loss: 0.0112491632\n",
      "Epoch [2860/10000], Training Loss: 0.0011853845, Validation Loss: 0.0112329563\n",
      "Epoch [2880/10000], Training Loss: 0.0011602016, Validation Loss: 0.0112165064\n",
      "Epoch [2900/10000], Training Loss: 0.0011357274, Validation Loss: 0.0112000592\n",
      "Epoch [2920/10000], Training Loss: 0.0011145801, Validation Loss: 0.0112300636\n",
      "Epoch [2940/10000], Training Loss: 0.0010894565, Validation Loss: 0.0111523522\n",
      "Epoch [2960/10000], Training Loss: 0.0010666191, Validation Loss: 0.0111425435\n",
      "Epoch [2980/10000], Training Loss: 0.0010448854, Validation Loss: 0.0111311916\n",
      "Epoch [3000/10000], Training Loss: 0.0010237442, Validation Loss: 0.0111111421\n",
      "Epoch [3020/10000], Training Loss: 0.0010031811, Validation Loss: 0.0110932896\n",
      "Epoch [3040/10000], Training Loss: 0.0009831687, Validation Loss: 0.0110742543\n",
      "Epoch [3060/10000], Training Loss: 0.0009636899, Validation Loss: 0.0110551640\n",
      "Epoch [3080/10000], Training Loss: 0.0009447268, Validation Loss: 0.0110357273\n",
      "Epoch [3100/10000], Training Loss: 0.0009262618, Validation Loss: 0.0110159209\n",
      "Epoch [3120/10000], Training Loss: 0.0009085687, Validation Loss: 0.0109791933\n",
      "Epoch [3140/10000], Training Loss: 0.0008920901, Validation Loss: 0.0109565975\n",
      "Epoch [3160/10000], Training Loss: 0.0008739787, Validation Loss: 0.0109483525\n",
      "Epoch [3180/10000], Training Loss: 0.0008574722, Validation Loss: 0.0109372474\n",
      "Epoch [3200/10000], Training Loss: 0.0008413941, Validation Loss: 0.0109143844\n",
      "Epoch [3220/10000], Training Loss: 0.0008257365, Validation Loss: 0.0108932061\n",
      "Epoch [3240/10000], Training Loss: 0.0008104697, Validation Loss: 0.0108709671\n",
      "Epoch [3260/10000], Training Loss: 0.0007955830, Validation Loss: 0.0108487802\n",
      "Epoch [3280/10000], Training Loss: 0.0007810643, Validation Loss: 0.0108261816\n",
      "Epoch [3300/10000], Training Loss: 0.0007669014, Validation Loss: 0.0108031211\n",
      "Epoch [3320/10000], Training Loss: 0.0007530905, Validation Loss: 0.0107819866\n",
      "Epoch [3340/10000], Training Loss: 0.0007402989, Validation Loss: 0.0107214283\n",
      "Epoch [3360/10000], Training Loss: 0.0007268670, Validation Loss: 0.0107368240\n",
      "Epoch [3380/10000], Training Loss: 0.0007139698, Validation Loss: 0.0107145421\n",
      "Epoch [3400/10000], Training Loss: 0.0007015204, Validation Loss: 0.0106838346\n",
      "Epoch [3420/10000], Training Loss: 0.0006894104, Validation Loss: 0.0106593873\n",
      "Epoch [3440/10000], Training Loss: 0.0006775855, Validation Loss: 0.0106335441\n",
      "Epoch [3460/10000], Training Loss: 0.0006660345, Validation Loss: 0.0106077902\n",
      "Epoch [3480/10000], Training Loss: 0.0006547495, Validation Loss: 0.0105813537\n",
      "Epoch [3500/10000], Training Loss: 0.0006437227, Validation Loss: 0.0105545595\n",
      "Epoch [3520/10000], Training Loss: 0.0006329461, Validation Loss: 0.0105272299\n",
      "Epoch [3540/10000], Training Loss: 0.0006224135, Validation Loss: 0.0105002709\n",
      "Epoch [3560/10000], Training Loss: 0.0006214189, Validation Loss: 0.0105158323\n",
      "Epoch [3580/10000], Training Loss: 0.0006033595, Validation Loss: 0.0104622357\n",
      "Epoch [3600/10000], Training Loss: 0.0005926307, Validation Loss: 0.0104199247\n",
      "Epoch [3620/10000], Training Loss: 0.0005830966, Validation Loss: 0.0103912987\n",
      "Epoch [3640/10000], Training Loss: 0.0005738306, Validation Loss: 0.0103629669\n",
      "Epoch [3660/10000], Training Loss: 0.0005647719, Validation Loss: 0.0103331860\n",
      "Epoch [3680/10000], Training Loss: 0.0005559088, Validation Loss: 0.0103038689\n",
      "Epoch [3700/10000], Training Loss: 0.0005472341, Validation Loss: 0.0102743665\n",
      "Epoch [3720/10000], Training Loss: 0.0005387422, Validation Loss: 0.0102444477\n",
      "Epoch [3740/10000], Training Loss: 0.0005304280, Validation Loss: 0.0102141500\n",
      "Epoch [3760/10000], Training Loss: 0.0005222872, Validation Loss: 0.0101835374\n",
      "Epoch [3780/10000], Training Loss: 0.0005143142, Validation Loss: 0.0101526221\n",
      "Epoch [3800/10000], Training Loss: 0.0005065064, Validation Loss: 0.0101224259\n",
      "Epoch [3820/10000], Training Loss: 0.0005108960, Validation Loss: 0.0101511190\n",
      "Epoch [3840/10000], Training Loss: 0.0004919225, Validation Loss: 0.0100848051\n",
      "Epoch [3860/10000], Training Loss: 0.0004843074, Validation Loss: 0.0100369621\n",
      "Epoch [3880/10000], Training Loss: 0.0004772627, Validation Loss: 0.0099993404\n",
      "Epoch [3900/10000], Training Loss: 0.0004703315, Validation Loss: 0.0099689001\n",
      "Epoch [3920/10000], Training Loss: 0.0004635503, Validation Loss: 0.0099388575\n",
      "Epoch [3940/10000], Training Loss: 0.0004569006, Validation Loss: 0.0099071451\n",
      "Epoch [3960/10000], Training Loss: 0.0004503794, Validation Loss: 0.0098754633\n",
      "Epoch [3980/10000], Training Loss: 0.0004439830, Validation Loss: 0.0098436475\n",
      "Epoch [4000/10000], Training Loss: 0.0004377081, Validation Loss: 0.0098115997\n",
      "Epoch [4020/10000], Training Loss: 0.0004315515, Validation Loss: 0.0097793965\n",
      "Epoch [4040/10000], Training Loss: 0.0004255192, Validation Loss: 0.0097495122\n",
      "Epoch [4060/10000], Training Loss: 0.0004200174, Validation Loss: 0.0096768700\n",
      "Epoch [4080/10000], Training Loss: 0.0004142941, Validation Loss: 0.0096869431\n",
      "Epoch [4100/10000], Training Loss: 0.0004084693, Validation Loss: 0.0096590985\n",
      "Epoch [4120/10000], Training Loss: 0.0004028762, Validation Loss: 0.0096261697\n",
      "Epoch [4140/10000], Training Loss: 0.0003974949, Validation Loss: 0.0095915571\n",
      "Epoch [4160/10000], Training Loss: 0.0003922115, Validation Loss: 0.0095612919\n",
      "Epoch [4180/10000], Training Loss: 0.0003870231, Validation Loss: 0.0095293261\n",
      "Epoch [4200/10000], Training Loss: 0.0003819262, Validation Loss: 0.0094977003\n",
      "Epoch [4220/10000], Training Loss: 0.0003769179, Validation Loss: 0.0094659319\n",
      "Epoch [4240/10000], Training Loss: 0.0003719961, Validation Loss: 0.0094340490\n",
      "Epoch [4260/10000], Training Loss: 0.0003671585, Validation Loss: 0.0094020460\n",
      "Epoch [4280/10000], Training Loss: 0.0003624032, Validation Loss: 0.0093698734\n",
      "Epoch [4300/10000], Training Loss: 0.0003591488, Validation Loss: 0.0093058078\n",
      "Epoch [4320/10000], Training Loss: 0.0003552618, Validation Loss: 0.0093557443\n",
      "Epoch [4340/10000], Training Loss: 0.0003491996, Validation Loss: 0.0092813792\n",
      "Epoch [4360/10000], Training Loss: 0.0003446507, Validation Loss: 0.0092448983\n",
      "Epoch [4380/10000], Training Loss: 0.0003404109, Validation Loss: 0.0092190644\n",
      "Epoch [4400/10000], Training Loss: 0.0003362590, Validation Loss: 0.0091900900\n",
      "Epoch [4420/10000], Training Loss: 0.0003321814, Validation Loss: 0.0091603138\n",
      "Epoch [4440/10000], Training Loss: 0.0003281697, Validation Loss: 0.0091304965\n",
      "Epoch [4460/10000], Training Loss: 0.0003242209, Validation Loss: 0.0091004092\n",
      "Epoch [4480/10000], Training Loss: 0.0003203338, Validation Loss: 0.0090701869\n",
      "Epoch [4500/10000], Training Loss: 0.0003165066, Validation Loss: 0.0090399534\n",
      "Epoch [4520/10000], Training Loss: 0.0003127384, Validation Loss: 0.0090096900\n",
      "Epoch [4540/10000], Training Loss: 0.0003090271, Validation Loss: 0.0089793829\n",
      "Epoch [4560/10000], Training Loss: 0.0003053722, Validation Loss: 0.0089490674\n",
      "Epoch [4580/10000], Training Loss: 0.0003017719, Validation Loss: 0.0089187454\n",
      "Epoch [4600/10000], Training Loss: 0.0002982364, Validation Loss: 0.0088908952\n",
      "Epoch [4620/10000], Training Loss: 0.0002974645, Validation Loss: 0.0088087833\n",
      "Epoch [4640/10000], Training Loss: 0.0002915558, Validation Loss: 0.0088162990\n",
      "Epoch [4660/10000], Training Loss: 0.0002882025, Validation Loss: 0.0087968372\n",
      "Epoch [4680/10000], Training Loss: 0.0002849489, Validation Loss: 0.0087739434\n",
      "Epoch [4700/10000], Training Loss: 0.0002817763, Validation Loss: 0.0087475525\n",
      "Epoch [4720/10000], Training Loss: 0.0002786416, Validation Loss: 0.0087183481\n",
      "Epoch [4740/10000], Training Loss: 0.0002755540, Validation Loss: 0.0086898664\n",
      "Epoch [4760/10000], Training Loss: 0.0002725091, Validation Loss: 0.0086613903\n",
      "Epoch [4780/10000], Training Loss: 0.0002695064, Validation Loss: 0.0086329402\n",
      "Epoch [4800/10000], Training Loss: 0.0002665447, Validation Loss: 0.0086044325\n",
      "Epoch [4820/10000], Training Loss: 0.0002636230, Validation Loss: 0.0085759033\n",
      "Epoch [4840/10000], Training Loss: 0.0002607408, Validation Loss: 0.0085473051\n",
      "Epoch [4860/10000], Training Loss: 0.0002579259, Validation Loss: 0.0085151419\n",
      "Epoch [4880/10000], Training Loss: 0.0002577997, Validation Loss: 0.0085420972\n",
      "Epoch [4900/10000], Training Loss: 0.0002532044, Validation Loss: 0.0084611438\n",
      "Epoch [4920/10000], Training Loss: 0.0002499319, Validation Loss: 0.0084314086\n",
      "Epoch [4940/10000], Training Loss: 0.0002472127, Validation Loss: 0.0084124459\n",
      "Epoch [4960/10000], Training Loss: 0.0002446272, Validation Loss: 0.0083841188\n",
      "Epoch [4980/10000], Training Loss: 0.0002420875, Validation Loss: 0.0083575789\n",
      "Epoch [5000/10000], Training Loss: 0.0002395800, Validation Loss: 0.0083303247\n",
      "Epoch [5020/10000], Training Loss: 0.0002371046, Validation Loss: 0.0083033601\n",
      "Epoch [5040/10000], Training Loss: 0.0002346597, Validation Loss: 0.0082763573\n",
      "Epoch [5060/10000], Training Loss: 0.0002322450, Validation Loss: 0.0082492987\n",
      "Epoch [5080/10000], Training Loss: 0.0002298599, Validation Loss: 0.0082220286\n",
      "Epoch [5100/10000], Training Loss: 0.0002299263, Validation Loss: 0.0081628393\n",
      "Epoch [5120/10000], Training Loss: 0.0002258375, Validation Loss: 0.0081844339\n",
      "Epoch [5140/10000], Training Loss: 0.0002231397, Validation Loss: 0.0081494804\n",
      "Epoch [5160/10000], Training Loss: 0.0002209136, Validation Loss: 0.0081193224\n",
      "Epoch [5180/10000], Training Loss: 0.0002187268, Validation Loss: 0.0080932118\n",
      "Epoch [5200/10000], Training Loss: 0.0002165919, Validation Loss: 0.0080694640\n",
      "Epoch [5220/10000], Training Loss: 0.0002144898, Validation Loss: 0.0080439048\n",
      "Epoch [5240/10000], Training Loss: 0.0002124123, Validation Loss: 0.0080186334\n",
      "Epoch [5260/10000], Training Loss: 0.0002103582, Validation Loss: 0.0079931412\n",
      "Epoch [5280/10000], Training Loss: 0.0002083274, Validation Loss: 0.0079677142\n",
      "Epoch [5300/10000], Training Loss: 0.0002063195, Validation Loss: 0.0079422565\n",
      "Epoch [5320/10000], Training Loss: 0.0002043338, Validation Loss: 0.0079167550\n",
      "Epoch [5340/10000], Training Loss: 0.0002023702, Validation Loss: 0.0078913933\n",
      "Epoch [5360/10000], Training Loss: 0.0002016203, Validation Loss: 0.0078887437\n",
      "Epoch [5380/10000], Training Loss: 0.0002045494, Validation Loss: 0.0078690257\n",
      "Epoch [5400/10000], Training Loss: 0.0001975342, Validation Loss: 0.0078287059\n",
      "Epoch [5420/10000], Training Loss: 0.0001950608, Validation Loss: 0.0077992552\n",
      "Epoch [5440/10000], Training Loss: 0.0001931812, Validation Loss: 0.0077718799\n",
      "Epoch [5460/10000], Training Loss: 0.0001914245, Validation Loss: 0.0077458466\n",
      "Epoch [5480/10000], Training Loss: 0.0001896836, Validation Loss: 0.0077225785\n",
      "Epoch [5500/10000], Training Loss: 0.0001879621, Validation Loss: 0.0076983063\n",
      "Epoch [5520/10000], Training Loss: 0.0001862583, Validation Loss: 0.0076743155\n",
      "Epoch [5540/10000], Training Loss: 0.0001845717, Validation Loss: 0.0076502245\n",
      "Epoch [5560/10000], Training Loss: 0.0001829022, Validation Loss: 0.0076260692\n",
      "Epoch [5580/10000], Training Loss: 0.0001812494, Validation Loss: 0.0076018875\n",
      "Epoch [5600/10000], Training Loss: 0.0001796133, Validation Loss: 0.0075775436\n",
      "Epoch [5620/10000], Training Loss: 0.0001784112, Validation Loss: 0.0075411471\n",
      "Epoch [5640/10000], Training Loss: 0.0001793094, Validation Loss: 0.0074958019\n",
      "Epoch [5660/10000], Training Loss: 0.0001750565, Validation Loss: 0.0074980762\n",
      "Epoch [5680/10000], Training Loss: 0.0001734233, Validation Loss: 0.0074837906\n",
      "Epoch [5700/10000], Training Loss: 0.0001719532, Validation Loss: 0.0074640582\n",
      "Epoch [5720/10000], Training Loss: 0.0001704663, Validation Loss: 0.0074400124\n",
      "Epoch [5740/10000], Training Loss: 0.0001690092, Validation Loss: 0.0074167117\n",
      "Epoch [5760/10000], Training Loss: 0.0001675657, Validation Loss: 0.0073940135\n",
      "Epoch [5780/10000], Training Loss: 0.0001661352, Validation Loss: 0.0073711229\n",
      "Epoch [5800/10000], Training Loss: 0.0001647179, Validation Loss: 0.0073481281\n",
      "Epoch [5820/10000], Training Loss: 0.0001633135, Validation Loss: 0.0073250975\n",
      "Epoch [5840/10000], Training Loss: 0.0001619217, Validation Loss: 0.0073020495\n",
      "Epoch [5860/10000], Training Loss: 0.0001605425, Validation Loss: 0.0072790789\n",
      "Epoch [5880/10000], Training Loss: 0.0001599389, Validation Loss: 0.0072717844\n",
      "Epoch [5900/10000], Training Loss: 0.0001636306, Validation Loss: 0.0072841058\n",
      "Epoch [5920/10000], Training Loss: 0.0001568175, Validation Loss: 0.0072264327\n",
      "Epoch [5940/10000], Training Loss: 0.0001553291, Validation Loss: 0.0071916473\n",
      "Epoch [5960/10000], Training Loss: 0.0001540755, Validation Loss: 0.0071673212\n",
      "Epoch [5980/10000], Training Loss: 0.0001528154, Validation Loss: 0.0071473494\n",
      "Epoch [6000/10000], Training Loss: 0.0001515780, Validation Loss: 0.0071249967\n",
      "Epoch [6020/10000], Training Loss: 0.0001503522, Validation Loss: 0.0071033435\n",
      "Epoch [6040/10000], Training Loss: 0.0001491367, Validation Loss: 0.0070813610\n",
      "Epoch [6060/10000], Training Loss: 0.0001479314, Validation Loss: 0.0070593413\n",
      "Epoch [6080/10000], Training Loss: 0.0001467357, Validation Loss: 0.0070372731\n",
      "Epoch [6100/10000], Training Loss: 0.0001455502, Validation Loss: 0.0070151724\n",
      "Epoch [6120/10000], Training Loss: 0.0001443792, Validation Loss: 0.0069919256\n",
      "Epoch [6140/10000], Training Loss: 0.0001701320, Validation Loss: 0.0069147097\n",
      "Epoch [6160/10000], Training Loss: 0.0001422397, Validation Loss: 0.0069353185\n",
      "Epoch [6180/10000], Training Loss: 0.0001411457, Validation Loss: 0.0069316295\n",
      "Epoch [6200/10000], Training Loss: 0.0001399785, Validation Loss: 0.0069131139\n",
      "Epoch [6220/10000], Training Loss: 0.0001388679, Validation Loss: 0.0068880087\n",
      "Epoch [6240/10000], Training Loss: 0.0001377962, Validation Loss: 0.0068676113\n",
      "Epoch [6260/10000], Training Loss: 0.0001367366, Validation Loss: 0.0068463199\n",
      "Epoch [6280/10000], Training Loss: 0.0001356855, Validation Loss: 0.0068254289\n",
      "Epoch [6300/10000], Training Loss: 0.0001346426, Validation Loss: 0.0068044104\n",
      "Epoch [6320/10000], Training Loss: 0.0001336075, Validation Loss: 0.0067833830\n",
      "Epoch [6340/10000], Training Loss: 0.0001325803, Validation Loss: 0.0067623015\n",
      "Epoch [6360/10000], Training Loss: 0.0001315611, Validation Loss: 0.0067411857\n",
      "Epoch [6380/10000], Training Loss: 0.0001305496, Validation Loss: 0.0067200530\n",
      "Epoch [6400/10000], Training Loss: 0.0001296191, Validation Loss: 0.0067038070\n",
      "Epoch [6420/10000], Training Loss: 0.0001417416, Validation Loss: 0.0067660818\n",
      "Epoch [6440/10000], Training Loss: 0.0001293270, Validation Loss: 0.0066479412\n",
      "Epoch [6460/10000], Training Loss: 0.0001270571, Validation Loss: 0.0066486136\n",
      "Epoch [6480/10000], Training Loss: 0.0001259179, Validation Loss: 0.0066203349\n",
      "Epoch [6500/10000], Training Loss: 0.0001250050, Validation Loss: 0.0066046161\n",
      "Epoch [6520/10000], Training Loss: 0.0001241231, Validation Loss: 0.0065851985\n",
      "Epoch [6540/10000], Training Loss: 0.0001232464, Validation Loss: 0.0065657953\n",
      "Epoch [6560/10000], Training Loss: 0.0001223765, Validation Loss: 0.0065467996\n",
      "Epoch [6580/10000], Training Loss: 0.0001215126, Validation Loss: 0.0065277615\n",
      "Epoch [6600/10000], Training Loss: 0.0001206548, Validation Loss: 0.0065087145\n",
      "Epoch [6620/10000], Training Loss: 0.0001198031, Validation Loss: 0.0064896522\n",
      "Epoch [6640/10000], Training Loss: 0.0001189573, Validation Loss: 0.0064705731\n",
      "Epoch [6660/10000], Training Loss: 0.0001181174, Validation Loss: 0.0064515071\n",
      "Epoch [6680/10000], Training Loss: 0.0001172834, Validation Loss: 0.0064324257\n",
      "Epoch [6700/10000], Training Loss: 0.0001164552, Validation Loss: 0.0064133415\n",
      "Epoch [6720/10000], Training Loss: 0.0001156328, Validation Loss: 0.0063942559\n",
      "Epoch [6740/10000], Training Loss: 0.0001148164, Validation Loss: 0.0063751657\n",
      "Epoch [6760/10000], Training Loss: 0.0001140055, Validation Loss: 0.0063560447\n",
      "Epoch [6780/10000], Training Loss: 0.0001132153, Validation Loss: 0.0063351914\n",
      "Epoch [6800/10000], Training Loss: 0.0001182277, Validation Loss: 0.0063112923\n",
      "Epoch [6820/10000], Training Loss: 0.0001136824, Validation Loss: 0.0062867901\n",
      "Epoch [6840/10000], Training Loss: 0.0001109181, Validation Loss: 0.0062802127\n",
      "Epoch [6860/10000], Training Loss: 0.0001102115, Validation Loss: 0.0062677721\n",
      "Epoch [6880/10000], Training Loss: 0.0001094358, Validation Loss: 0.0062470865\n",
      "Epoch [6900/10000], Training Loss: 0.0001086992, Validation Loss: 0.0062300432\n",
      "Epoch [6920/10000], Training Loss: 0.0001079703, Validation Loss: 0.0062118727\n",
      "Epoch [6940/10000], Training Loss: 0.0001072468, Validation Loss: 0.0061941468\n",
      "Epoch [6960/10000], Training Loss: 0.0001065281, Validation Loss: 0.0061764549\n",
      "Epoch [6980/10000], Training Loss: 0.0001058142, Validation Loss: 0.0061587570\n",
      "Epoch [7000/10000], Training Loss: 0.0001051050, Validation Loss: 0.0061410856\n",
      "Epoch [7020/10000], Training Loss: 0.0001044063, Validation Loss: 0.0061246241\n",
      "Epoch [7040/10000], Training Loss: 0.0001349223, Validation Loss: 0.0061788042\n",
      "Epoch [7060/10000], Training Loss: 0.0001031214, Validation Loss: 0.0061120773\n",
      "Epoch [7080/10000], Training Loss: 0.0001025563, Validation Loss: 0.0060739918\n",
      "Epoch [7100/10000], Training Loss: 0.0001017956, Validation Loss: 0.0060545951\n",
      "Epoch [7120/10000], Training Loss: 0.0001011101, Validation Loss: 0.0060415501\n",
      "Epoch [7140/10000], Training Loss: 0.0001004641, Validation Loss: 0.0060244617\n",
      "Epoch [7160/10000], Training Loss: 0.0000998262, Validation Loss: 0.0060084364\n",
      "Epoch [7180/10000], Training Loss: 0.0000991927, Validation Loss: 0.0059919818\n",
      "Epoch [7200/10000], Training Loss: 0.0000985632, Validation Loss: 0.0059756921\n",
      "Epoch [7220/10000], Training Loss: 0.0000979374, Validation Loss: 0.0059594330\n",
      "Epoch [7240/10000], Training Loss: 0.0000973154, Validation Loss: 0.0059431880\n",
      "Epoch [7260/10000], Training Loss: 0.0000966974, Validation Loss: 0.0059268717\n",
      "Epoch [7280/10000], Training Loss: 0.0000964445, Validation Loss: 0.0059009409\n",
      "Epoch [7300/10000], Training Loss: 0.0000956235, Validation Loss: 0.0058820872\n",
      "Epoch [7320/10000], Training Loss: 0.0000955013, Validation Loss: 0.0058825957\n",
      "Epoch [7340/10000], Training Loss: 0.0000945408, Validation Loss: 0.0058702948\n",
      "Epoch [7360/10000], Training Loss: 0.0000937927, Validation Loss: 0.0058526648\n",
      "Epoch [7380/10000], Training Loss: 0.0000932311, Validation Loss: 0.0058356142\n",
      "Epoch [7400/10000], Training Loss: 0.0000926694, Validation Loss: 0.0058216248\n",
      "Epoch [7420/10000], Training Loss: 0.0000921127, Validation Loss: 0.0058064437\n",
      "Epoch [7440/10000], Training Loss: 0.0000915595, Validation Loss: 0.0057915747\n",
      "Epoch [7460/10000], Training Loss: 0.0000910094, Validation Loss: 0.0057767411\n",
      "Epoch [7480/10000], Training Loss: 0.0000904623, Validation Loss: 0.0057619363\n",
      "Epoch [7500/10000], Training Loss: 0.0000899181, Validation Loss: 0.0057471464\n",
      "Epoch [7520/10000], Training Loss: 0.0000893774, Validation Loss: 0.0057326490\n",
      "Epoch [7540/10000], Training Loss: 0.0000920983, Validation Loss: 0.0057475991\n",
      "Epoch [7560/10000], Training Loss: 0.0000942868, Validation Loss: 0.0057332334\n",
      "Epoch [7580/10000], Training Loss: 0.0000884332, Validation Loss: 0.0057044830\n",
      "Epoch [7600/10000], Training Loss: 0.0000873555, Validation Loss: 0.0056780004\n",
      "Epoch [7620/10000], Training Loss: 0.0000868345, Validation Loss: 0.0056625591\n",
      "Epoch [7640/10000], Training Loss: 0.0000863369, Validation Loss: 0.0056503974\n",
      "Epoch [7660/10000], Training Loss: 0.0000858438, Validation Loss: 0.0056361440\n",
      "Epoch [7680/10000], Training Loss: 0.0000853536, Validation Loss: 0.0056223595\n",
      "Epoch [7700/10000], Training Loss: 0.0000848658, Validation Loss: 0.0056087892\n",
      "Epoch [7720/10000], Training Loss: 0.0000843803, Validation Loss: 0.0055952044\n",
      "Epoch [7740/10000], Training Loss: 0.0000838974, Validation Loss: 0.0055816057\n",
      "Epoch [7760/10000], Training Loss: 0.0000834169, Validation Loss: 0.0055679050\n",
      "Epoch [7780/10000], Training Loss: 0.0000838698, Validation Loss: 0.0055401213\n",
      "Epoch [7800/10000], Training Loss: 0.0000859931, Validation Loss: 0.0055081332\n",
      "Epoch [7820/10000], Training Loss: 0.0000821858, Validation Loss: 0.0055245608\n",
      "Epoch [7840/10000], Training Loss: 0.0000817530, Validation Loss: 0.0055207959\n",
      "Epoch [7860/10000], Training Loss: 0.0000811585, Validation Loss: 0.0055048596\n",
      "Epoch [7880/10000], Training Loss: 0.0000807144, Validation Loss: 0.0054921908\n",
      "Epoch [7900/10000], Training Loss: 0.0000802764, Validation Loss: 0.0054800292\n",
      "Epoch [7920/10000], Training Loss: 0.0000798402, Validation Loss: 0.0054675969\n",
      "Epoch [7940/10000], Training Loss: 0.0000794059, Validation Loss: 0.0054550436\n",
      "Epoch [7960/10000], Training Loss: 0.0000789735, Validation Loss: 0.0054425406\n",
      "Epoch [7980/10000], Training Loss: 0.0000785432, Validation Loss: 0.0054301010\n",
      "Epoch [8000/10000], Training Loss: 0.0000781145, Validation Loss: 0.0054176385\n",
      "Epoch [8020/10000], Training Loss: 0.0000777237, Validation Loss: 0.0054025077\n",
      "Epoch [8040/10000], Training Loss: 0.0000786734, Validation Loss: 0.0054334975\n",
      "Epoch [8060/10000], Training Loss: 0.0000787236, Validation Loss: 0.0053774272\n",
      "Epoch [8080/10000], Training Loss: 0.0000767053, Validation Loss: 0.0053678416\n",
      "Epoch [8100/10000], Training Loss: 0.0000761035, Validation Loss: 0.0053611845\n",
      "Epoch [8120/10000], Training Loss: 0.0000756965, Validation Loss: 0.0053489478\n",
      "Epoch [8140/10000], Training Loss: 0.0000753053, Validation Loss: 0.0053368658\n",
      "Epoch [8160/10000], Training Loss: 0.0000749155, Validation Loss: 0.0053254627\n",
      "Epoch [8180/10000], Training Loss: 0.0000745271, Validation Loss: 0.0053140740\n",
      "Epoch [8200/10000], Training Loss: 0.0000741403, Validation Loss: 0.0053026564\n",
      "Epoch [8220/10000], Training Loss: 0.0000737550, Validation Loss: 0.0052912603\n",
      "Epoch [8240/10000], Training Loss: 0.0000733710, Validation Loss: 0.0052798698\n",
      "Epoch [8260/10000], Training Loss: 0.0000729896, Validation Loss: 0.0052680704\n",
      "Epoch [8280/10000], Training Loss: 0.0000859906, Validation Loss: 0.0052086958\n",
      "Epoch [8300/10000], Training Loss: 0.0000734424, Validation Loss: 0.0052853813\n",
      "Epoch [8320/10000], Training Loss: 0.0000720831, Validation Loss: 0.0052443813\n",
      "Epoch [8340/10000], Training Loss: 0.0000716279, Validation Loss: 0.0052260114\n",
      "Epoch [8360/10000], Training Loss: 0.0000712036, Validation Loss: 0.0052177254\n",
      "Epoch [8380/10000], Training Loss: 0.0000708448, Validation Loss: 0.0052057523\n",
      "Epoch [8400/10000], Training Loss: 0.0000704939, Validation Loss: 0.0051954868\n",
      "Epoch [8420/10000], Training Loss: 0.0000701448, Validation Loss: 0.0051849498\n",
      "Epoch [8440/10000], Training Loss: 0.0000697971, Validation Loss: 0.0051744254\n",
      "Epoch [8460/10000], Training Loss: 0.0000694504, Validation Loss: 0.0051639918\n",
      "Epoch [8480/10000], Training Loss: 0.0000691049, Validation Loss: 0.0051535587\n",
      "Epoch [8500/10000], Training Loss: 0.0000687605, Validation Loss: 0.0051430562\n",
      "Epoch [8520/10000], Training Loss: 0.0000687397, Validation Loss: 0.0051247585\n",
      "Epoch [8540/10000], Training Loss: 0.0000730876, Validation Loss: 0.0051439311\n",
      "Epoch [8560/10000], Training Loss: 0.0000693808, Validation Loss: 0.0051324791\n",
      "Epoch [8580/10000], Training Loss: 0.0000674793, Validation Loss: 0.0051099220\n",
      "Epoch [8600/10000], Training Loss: 0.0000671645, Validation Loss: 0.0050946814\n",
      "Epoch [8620/10000], Training Loss: 0.0000668245, Validation Loss: 0.0050867712\n",
      "Epoch [8640/10000], Training Loss: 0.0000665060, Validation Loss: 0.0050761253\n",
      "Epoch [8660/10000], Training Loss: 0.0000661908, Validation Loss: 0.0050666821\n",
      "Epoch [8680/10000], Training Loss: 0.0000658768, Validation Loss: 0.0050571398\n",
      "Epoch [8700/10000], Training Loss: 0.0000655635, Validation Loss: 0.0050475579\n",
      "Epoch [8720/10000], Training Loss: 0.0000652511, Validation Loss: 0.0050380277\n",
      "Epoch [8740/10000], Training Loss: 0.0000649396, Validation Loss: 0.0050285319\n",
      "Epoch [8760/10000], Training Loss: 0.0000646338, Validation Loss: 0.0050181276\n",
      "Epoch [8780/10000], Training Loss: 0.0001042069, Validation Loss: 0.0049401270\n",
      "Epoch [8800/10000], Training Loss: 0.0000649603, Validation Loss: 0.0050017959\n",
      "Epoch [8820/10000], Training Loss: 0.0000642118, Validation Loss: 0.0049977191\n",
      "Epoch [8840/10000], Training Loss: 0.0000634676, Validation Loss: 0.0049862964\n",
      "Epoch [8860/10000], Training Loss: 0.0000631844, Validation Loss: 0.0049754637\n",
      "Epoch [8880/10000], Training Loss: 0.0000628929, Validation Loss: 0.0049682767\n",
      "Epoch [8900/10000], Training Loss: 0.0000626066, Validation Loss: 0.0049588322\n",
      "Epoch [8920/10000], Training Loss: 0.0000623220, Validation Loss: 0.0049501127\n",
      "Epoch [8940/10000], Training Loss: 0.0000620380, Validation Loss: 0.0049414551\n",
      "Epoch [8960/10000], Training Loss: 0.0000617545, Validation Loss: 0.0049328185\n",
      "Epoch [8980/10000], Training Loss: 0.0000614715, Validation Loss: 0.0049241744\n",
      "Epoch [9000/10000], Training Loss: 0.0000611893, Validation Loss: 0.0049154866\n",
      "Epoch [9020/10000], Training Loss: 0.0000612558, Validation Loss: 0.0048989854\n",
      "Epoch [9040/10000], Training Loss: 0.0000656968, Validation Loss: 0.0049211313\n",
      "Epoch [9060/10000], Training Loss: 0.0000620242, Validation Loss: 0.0049110539\n",
      "Epoch [9080/10000], Training Loss: 0.0000601469, Validation Loss: 0.0048896587\n",
      "Epoch [9100/10000], Training Loss: 0.0000598864, Validation Loss: 0.0048761964\n",
      "Epoch [9120/10000], Training Loss: 0.0000596024, Validation Loss: 0.0048698452\n",
      "Epoch [9140/10000], Training Loss: 0.0000593395, Validation Loss: 0.0048606591\n",
      "Epoch [9160/10000], Training Loss: 0.0000590795, Validation Loss: 0.0048529482\n",
      "Epoch [9180/10000], Training Loss: 0.0000588204, Validation Loss: 0.0048450595\n",
      "Epoch [9200/10000], Training Loss: 0.0000585616, Validation Loss: 0.0048371782\n",
      "Epoch [9220/10000], Training Loss: 0.0000583031, Validation Loss: 0.0048293434\n",
      "Epoch [9240/10000], Training Loss: 0.0000580451, Validation Loss: 0.0048215049\n",
      "Epoch [9260/10000], Training Loss: 0.0000578049, Validation Loss: 0.0048120292\n",
      "Epoch [9280/10000], Training Loss: 0.0000741396, Validation Loss: 0.0047701634\n",
      "Epoch [9300/10000], Training Loss: 0.0000579733, Validation Loss: 0.0047779540\n",
      "Epoch [9320/10000], Training Loss: 0.0000572939, Validation Loss: 0.0047924449\n",
      "Epoch [9340/10000], Training Loss: 0.0000568238, Validation Loss: 0.0047872523\n",
      "Epoch [9360/10000], Training Loss: 0.0000565850, Validation Loss: 0.0047788508\n",
      "Epoch [9380/10000], Training Loss: 0.0000563439, Validation Loss: 0.0047722296\n",
      "Epoch [9400/10000], Training Loss: 0.0000561057, Validation Loss: 0.0047647329\n",
      "Epoch [9420/10000], Training Loss: 0.0000558674, Validation Loss: 0.0047575501\n",
      "Epoch [9440/10000], Training Loss: 0.0000556294, Validation Loss: 0.0047503519\n",
      "Epoch [9460/10000], Training Loss: 0.0000553918, Validation Loss: 0.0047431909\n",
      "Epoch [9480/10000], Training Loss: 0.0000551541, Validation Loss: 0.0047360719\n",
      "Epoch [9500/10000], Training Loss: 0.0000549283, Validation Loss: 0.0047276593\n",
      "Epoch [9520/10000], Training Loss: 0.0000826531, Validation Loss: 0.0046698451\n",
      "Epoch [9540/10000], Training Loss: 0.0000547997, Validation Loss: 0.0046958537\n",
      "Epoch [9560/10000], Training Loss: 0.0000544628, Validation Loss: 0.0047087022\n",
      "Epoch [9580/10000], Training Loss: 0.0000540492, Validation Loss: 0.0047055464\n",
      "Epoch [9600/10000], Training Loss: 0.0000538166, Validation Loss: 0.0046972125\n",
      "Epoch [9620/10000], Training Loss: 0.0000535915, Validation Loss: 0.0046920092\n",
      "Epoch [9640/10000], Training Loss: 0.0000533714, Validation Loss: 0.0046847272\n",
      "Epoch [9660/10000], Training Loss: 0.0000531522, Validation Loss: 0.0046782447\n",
      "Epoch [9680/10000], Training Loss: 0.0000529332, Validation Loss: 0.0046717213\n",
      "Epoch [9700/10000], Training Loss: 0.0000527143, Validation Loss: 0.0046652532\n",
      "Epoch [9720/10000], Training Loss: 0.0000524954, Validation Loss: 0.0046587936\n",
      "Epoch [9740/10000], Training Loss: 0.0000522768, Validation Loss: 0.0046521993\n",
      "Epoch [9760/10000], Training Loss: 0.0000539370, Validation Loss: 0.0046285549\n",
      "Epoch [9780/10000], Training Loss: 0.0000607425, Validation Loss: 0.0045987414\n",
      "Epoch [9800/10000], Training Loss: 0.0000519644, Validation Loss: 0.0046207993\n",
      "Epoch [9820/10000], Training Loss: 0.0000515539, Validation Loss: 0.0046289125\n",
      "Epoch [9840/10000], Training Loss: 0.0000512568, Validation Loss: 0.0046243253\n",
      "Epoch [9860/10000], Training Loss: 0.0000510504, Validation Loss: 0.0046177008\n",
      "Epoch [9880/10000], Training Loss: 0.0000508474, Validation Loss: 0.0046125967\n",
      "Epoch [9900/10000], Training Loss: 0.0000506455, Validation Loss: 0.0046063401\n",
      "Epoch [9920/10000], Training Loss: 0.0000504436, Validation Loss: 0.0046003689\n",
      "Epoch [9940/10000], Training Loss: 0.0000502418, Validation Loss: 0.0045944140\n",
      "Epoch [9960/10000], Training Loss: 0.0000500400, Validation Loss: 0.0045885113\n",
      "Epoch [9980/10000], Training Loss: 0.0000498382, Validation Loss: 0.0045826519\n",
      "Epoch [10000/10000], Training Loss: 0.0000496369, Validation Loss: 0.0045770737\n",
      "Training finished!\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "# Initialize model\n",
    "input_size = x_train.shape[2]\n",
    "hidden_size = 32\n",
    "num_layers = 1\n",
    "output_size = 12\n",
    "model = LSTMModel(input_size, hidden_size, num_layers, output_size)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0003)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10000\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(0, 1):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(x_train, lengths)\n",
    "        loss = criterion(outputs, y_train)\n",
    "\n",
    "        # Backpropagation and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(x_validation, lengths_val)\n",
    "            val_loss = criterion(val_outputs, y_validation)\n",
    "    \n",
    "    \n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {loss.item():.10f}, Validation Loss: {val_loss.item():.10f}')\n",
    "\n",
    "print(\"Training finished!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T20:24:13.091856434Z",
     "start_time": "2023-08-29T20:23:43.202425962Z"
    }
   },
   "id": "56b99aeb675728f"
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/10000], Training Loss: 0.0089101819, Validation Loss: 0.0089048464\n",
      "Epoch [40/10000], Training Loss: 0.0022561706, Validation Loss: 0.0095982170\n",
      "Epoch [60/10000], Training Loss: 0.0005919900, Validation Loss: 0.0066674184\n",
      "Epoch [80/10000], Training Loss: 0.0002852711, Validation Loss: 0.0062750010\n",
      "Epoch [100/10000], Training Loss: 0.0001867977, Validation Loss: 0.0061051687\n",
      "Epoch [120/10000], Training Loss: 0.0001382053, Validation Loss: 0.0058311392\n",
      "Epoch [140/10000], Training Loss: 0.0001091015, Validation Loss: 0.0056471284\n",
      "Epoch [160/10000], Training Loss: 0.0000927501, Validation Loss: 0.0055286880\n",
      "Epoch [180/10000], Training Loss: 0.0000832239, Validation Loss: 0.0054362840\n",
      "Epoch [200/10000], Training Loss: 0.0000769824, Validation Loss: 0.0053604208\n",
      "Epoch [220/10000], Training Loss: 0.0000725170, Validation Loss: 0.0052981796\n",
      "Epoch [240/10000], Training Loss: 0.0000691370, Validation Loss: 0.0052483887\n",
      "Epoch [260/10000], Training Loss: 0.0000664721, Validation Loss: 0.0052079502\n",
      "Epoch [280/10000], Training Loss: 0.0000643035, Validation Loss: 0.0051740734\n",
      "Epoch [300/10000], Training Loss: 0.0000624948, Validation Loss: 0.0051446734\n",
      "Epoch [320/10000], Training Loss: 0.0000609571, Validation Loss: 0.0051184655\n",
      "Epoch [340/10000], Training Loss: 0.0000596299, Validation Loss: 0.0050946828\n",
      "Epoch [360/10000], Training Loss: 0.0000584706, Validation Loss: 0.0050728773\n",
      "Epoch [380/10000], Training Loss: 0.0000574478, Validation Loss: 0.0050527784\n",
      "Epoch [400/10000], Training Loss: 0.0000565384, Validation Loss: 0.0050341943\n",
      "Epoch [420/10000], Training Loss: 0.0000557241, Validation Loss: 0.0050169858\n",
      "Epoch [440/10000], Training Loss: 0.0000549905, Validation Loss: 0.0050009931\n",
      "Epoch [460/10000], Training Loss: 0.0000543263, Validation Loss: 0.0049860831\n",
      "Epoch [480/10000], Training Loss: 0.0000537217, Validation Loss: 0.0049720793\n",
      "Epoch [500/10000], Training Loss: 0.0000531689, Validation Loss: 0.0049588461\n",
      "Epoch [520/10000], Training Loss: 0.0000526608, Validation Loss: 0.0049462481\n",
      "Epoch [540/10000], Training Loss: 0.0000521915, Validation Loss: 0.0049341843\n",
      "Epoch [560/10000], Training Loss: 0.0000517560, Validation Loss: 0.0049225832\n",
      "Epoch [580/10000], Training Loss: 0.0000513501, Validation Loss: 0.0049113850\n",
      "Epoch [600/10000], Training Loss: 0.0000509698, Validation Loss: 0.0049005598\n",
      "Epoch [620/10000], Training Loss: 0.0000506121, Validation Loss: 0.0048900731\n",
      "Epoch [640/10000], Training Loss: 0.0000502742, Validation Loss: 0.0048799017\n",
      "Epoch [660/10000], Training Loss: 0.0000499538, Validation Loss: 0.0048700217\n",
      "Epoch [680/10000], Training Loss: 0.0000496488, Validation Loss: 0.0048604147\n",
      "Epoch [700/10000], Training Loss: 0.0000493577, Validation Loss: 0.0048510525\n",
      "Epoch [720/10000], Training Loss: 0.0000490787, Validation Loss: 0.0048419223\n",
      "Epoch [740/10000], Training Loss: 0.0000488108, Validation Loss: 0.0048329988\n",
      "Epoch [760/10000], Training Loss: 0.0000485527, Validation Loss: 0.0048242626\n",
      "Epoch [780/10000], Training Loss: 0.0000483033, Validation Loss: 0.0048156967\n",
      "Epoch [800/10000], Training Loss: 0.0000480620, Validation Loss: 0.0048072878\n",
      "Epoch [820/10000], Training Loss: 0.0000478277, Validation Loss: 0.0047990144\n",
      "Epoch [840/10000], Training Loss: 0.0000476000, Validation Loss: 0.0047908598\n",
      "Epoch [860/10000], Training Loss: 0.0000473781, Validation Loss: 0.0047828141\n",
      "Epoch [880/10000], Training Loss: 0.0000471614, Validation Loss: 0.0047748657\n",
      "Epoch [900/10000], Training Loss: 0.0000469495, Validation Loss: 0.0047670044\n",
      "Epoch [920/10000], Training Loss: 0.0000467420, Validation Loss: 0.0047592185\n",
      "Epoch [940/10000], Training Loss: 0.0000465384, Validation Loss: 0.0047515030\n",
      "Epoch [960/10000], Training Loss: 0.0000463383, Validation Loss: 0.0047438438\n",
      "Epoch [980/10000], Training Loss: 0.0000461416, Validation Loss: 0.0047362410\n",
      "Epoch [1000/10000], Training Loss: 0.0000459477, Validation Loss: 0.0047286772\n",
      "Epoch [1020/10000], Training Loss: 0.0000457565, Validation Loss: 0.0047211591\n",
      "Epoch [1040/10000], Training Loss: 0.0000455677, Validation Loss: 0.0047136797\n",
      "Epoch [1060/10000], Training Loss: 0.0000453812, Validation Loss: 0.0047062268\n",
      "Epoch [1080/10000], Training Loss: 0.0000451965, Validation Loss: 0.0046988032\n",
      "Epoch [1100/10000], Training Loss: 0.0000450139, Validation Loss: 0.0046913992\n",
      "Epoch [1120/10000], Training Loss: 0.0000448329, Validation Loss: 0.0046840138\n",
      "Epoch [1140/10000], Training Loss: 0.0000446534, Validation Loss: 0.0046766517\n",
      "Epoch [1160/10000], Training Loss: 0.0000444752, Validation Loss: 0.0046693026\n",
      "Epoch [1180/10000], Training Loss: 0.0000442984, Validation Loss: 0.0046619652\n",
      "Epoch [1200/10000], Training Loss: 0.0000441227, Validation Loss: 0.0046546371\n",
      "Epoch [1220/10000], Training Loss: 0.0000439480, Validation Loss: 0.0046473225\n",
      "Epoch [1240/10000], Training Loss: 0.0000437744, Validation Loss: 0.0046400055\n",
      "Epoch [1260/10000], Training Loss: 0.0000436016, Validation Loss: 0.0046326960\n",
      "Epoch [1280/10000], Training Loss: 0.0000434296, Validation Loss: 0.0046253996\n",
      "Epoch [1300/10000], Training Loss: 0.0000432584, Validation Loss: 0.0046180924\n",
      "Epoch [1320/10000], Training Loss: 0.0000430878, Validation Loss: 0.0046107941\n",
      "Epoch [1340/10000], Training Loss: 0.0000429179, Validation Loss: 0.0046034926\n",
      "Epoch [1360/10000], Training Loss: 0.0000427486, Validation Loss: 0.0045961887\n",
      "Epoch [1380/10000], Training Loss: 0.0000425798, Validation Loss: 0.0045888829\n",
      "Epoch [1400/10000], Training Loss: 0.0000424114, Validation Loss: 0.0045815818\n",
      "Epoch [1420/10000], Training Loss: 0.0000422436, Validation Loss: 0.0045742663\n",
      "Epoch [1440/10000], Training Loss: 0.0000420760, Validation Loss: 0.0045669521\n",
      "Epoch [1460/10000], Training Loss: 0.0000419090, Validation Loss: 0.0045596310\n",
      "Epoch [1480/10000], Training Loss: 0.0000417423, Validation Loss: 0.0045523127\n",
      "Epoch [1500/10000], Training Loss: 0.0000415759, Validation Loss: 0.0045449845\n",
      "Epoch [1520/10000], Training Loss: 0.0000414098, Validation Loss: 0.0045376467\n",
      "Epoch [1540/10000], Training Loss: 0.0000412440, Validation Loss: 0.0045303074\n",
      "Epoch [1560/10000], Training Loss: 0.0000410784, Validation Loss: 0.0045229648\n",
      "Epoch [1580/10000], Training Loss: 0.0000409131, Validation Loss: 0.0045156041\n",
      "Epoch [1600/10000], Training Loss: 0.0000407481, Validation Loss: 0.0045082453\n",
      "Epoch [1620/10000], Training Loss: 0.0000405832, Validation Loss: 0.0045008752\n",
      "Epoch [1640/10000], Training Loss: 0.0000404185, Validation Loss: 0.0044935015\n",
      "Epoch [1660/10000], Training Loss: 0.0000402541, Validation Loss: 0.0044861180\n",
      "Epoch [1680/10000], Training Loss: 0.0000400898, Validation Loss: 0.0044787335\n",
      "Epoch [1700/10000], Training Loss: 0.0000399257, Validation Loss: 0.0044713281\n",
      "Epoch [1720/10000], Training Loss: 0.0000397617, Validation Loss: 0.0044639297\n",
      "Epoch [1740/10000], Training Loss: 0.0000395979, Validation Loss: 0.0044565173\n",
      "Epoch [1760/10000], Training Loss: 0.0000394343, Validation Loss: 0.0044490923\n",
      "Epoch [1780/10000], Training Loss: 0.0000392707, Validation Loss: 0.0044416706\n",
      "Epoch [1800/10000], Training Loss: 0.0000391073, Validation Loss: 0.0044342317\n",
      "Epoch [1820/10000], Training Loss: 0.0000389440, Validation Loss: 0.0044268011\n",
      "Epoch [1840/10000], Training Loss: 0.0000387809, Validation Loss: 0.0044193757\n",
      "Epoch [1860/10000], Training Loss: 0.0000386182, Validation Loss: 0.0044124797\n",
      "Epoch [1880/10000], Training Loss: 0.0000462100, Validation Loss: 0.0045231585\n",
      "Epoch [1900/10000], Training Loss: 0.0002265714, Validation Loss: 0.0048794509\n",
      "Epoch [1920/10000], Training Loss: 0.0000830800, Validation Loss: 0.0047633969\n",
      "Epoch [1940/10000], Training Loss: 0.0000458429, Validation Loss: 0.0044781943\n",
      "Epoch [1960/10000], Training Loss: 0.0000401382, Validation Loss: 0.0044647101\n",
      "Epoch [1980/10000], Training Loss: 0.0000391668, Validation Loss: 0.0044436962\n",
      "Epoch [2000/10000], Training Loss: 0.0000386697, Validation Loss: 0.0044274474\n",
      "Epoch [2020/10000], Training Loss: 0.0000383717, Validation Loss: 0.0044159265\n",
      "Epoch [2040/10000], Training Loss: 0.0000381234, Validation Loss: 0.0044052475\n",
      "Epoch [2060/10000], Training Loss: 0.0000379004, Validation Loss: 0.0043957774\n",
      "Epoch [2080/10000], Training Loss: 0.0000376925, Validation Loss: 0.0043873200\n",
      "Epoch [2100/10000], Training Loss: 0.0000374955, Validation Loss: 0.0043789959\n",
      "Epoch [2120/10000], Training Loss: 0.0000588426, Validation Loss: 0.0042780749\n",
      "Epoch [2140/10000], Training Loss: 0.0004894744, Validation Loss: 0.0046186484\n",
      "Epoch [2160/10000], Training Loss: 0.0000963923, Validation Loss: 0.0044562742\n",
      "Epoch [2180/10000], Training Loss: 0.0000510691, Validation Loss: 0.0045268624\n",
      "Epoch [2200/10000], Training Loss: 0.0000417135, Validation Loss: 0.0045250366\n",
      "Epoch [2220/10000], Training Loss: 0.0000396334, Validation Loss: 0.0045097605\n",
      "Epoch [2240/10000], Training Loss: 0.0000388442, Validation Loss: 0.0044886116\n",
      "Epoch [2260/10000], Training Loss: 0.0000383296, Validation Loss: 0.0044753235\n",
      "Epoch [2280/10000], Training Loss: 0.0000379292, Validation Loss: 0.0044652955\n",
      "Epoch [2300/10000], Training Loss: 0.0000375908, Validation Loss: 0.0044561992\n",
      "Epoch [2320/10000], Training Loss: 0.0000372909, Validation Loss: 0.0044483002\n",
      "Epoch [2340/10000], Training Loss: 0.0000370176, Validation Loss: 0.0044405498\n",
      "Epoch [2360/10000], Training Loss: 0.0000367638, Validation Loss: 0.0044329469\n",
      "Epoch [2380/10000], Training Loss: 0.0000365488, Validation Loss: 0.0044230684\n",
      "Epoch [2400/10000], Training Loss: 0.0007010663, Validation Loss: 0.0045684143\n",
      "Epoch [2420/10000], Training Loss: 0.0001305237, Validation Loss: 0.0047289664\n",
      "Epoch [2440/10000], Training Loss: 0.0000498029, Validation Loss: 0.0044895154\n",
      "Epoch [2460/10000], Training Loss: 0.0000374395, Validation Loss: 0.0044630240\n",
      "Epoch [2480/10000], Training Loss: 0.0000389204, Validation Loss: 0.0044735800\n",
      "Epoch [2500/10000], Training Loss: 0.0008701499, Validation Loss: 0.0051646773\n",
      "Epoch [2520/10000], Training Loss: 0.0000554369, Validation Loss: 0.0045083025\n",
      "Epoch [2540/10000], Training Loss: 0.0000450462, Validation Loss: 0.0044138455\n",
      "Epoch [2560/10000], Training Loss: 0.0000377903, Validation Loss: 0.0045079226\n",
      "Epoch [2580/10000], Training Loss: 0.0000367174, Validation Loss: 0.0044647730\n",
      "Epoch [2600/10000], Training Loss: 0.0000361427, Validation Loss: 0.0044457116\n",
      "Epoch [2620/10000], Training Loss: 0.0000359320, Validation Loss: 0.0044425176\n",
      "Epoch [2640/10000], Training Loss: 0.0002235128, Validation Loss: 0.0047865519\n",
      "Epoch [2660/10000], Training Loss: 0.0001370953, Validation Loss: 0.0046907165\n",
      "Epoch [2680/10000], Training Loss: 0.0000582673, Validation Loss: 0.0045544039\n",
      "Epoch [2700/10000], Training Loss: 0.0000395884, Validation Loss: 0.0045577106\n",
      "Epoch [2720/10000], Training Loss: 0.0000369708, Validation Loss: 0.0045149522\n",
      "Epoch [2740/10000], Training Loss: 0.0000361509, Validation Loss: 0.0044921362\n",
      "Epoch [2760/10000], Training Loss: 0.0000357038, Validation Loss: 0.0044835624\n",
      "Epoch [2780/10000], Training Loss: 0.0000353667, Validation Loss: 0.0044715470\n",
      "Epoch [2800/10000], Training Loss: 0.0000351094, Validation Loss: 0.0044578426\n",
      "Epoch [2820/10000], Training Loss: 0.0004268093, Validation Loss: 0.0043130643\n",
      "Epoch [2840/10000], Training Loss: 0.0002747438, Validation Loss: 0.0050759530\n",
      "Epoch [2860/10000], Training Loss: 0.0000428621, Validation Loss: 0.0045232633\n",
      "Epoch [2880/10000], Training Loss: 0.0000392809, Validation Loss: 0.0045137079\n",
      "Epoch [2900/10000], Training Loss: 0.0000365786, Validation Loss: 0.0045379698\n",
      "Epoch [2920/10000], Training Loss: 0.0000358776, Validation Loss: 0.0045423172\n",
      "Epoch [2940/10000], Training Loss: 0.0000353753, Validation Loss: 0.0045227963\n",
      "Epoch [2960/10000], Training Loss: 0.0000349859, Validation Loss: 0.0045152782\n",
      "Epoch [2980/10000], Training Loss: 0.0000346541, Validation Loss: 0.0045057014\n",
      "Epoch [3000/10000], Training Loss: 0.0000343565, Validation Loss: 0.0044950452\n",
      "Epoch [3020/10000], Training Loss: 0.0000380118, Validation Loss: 0.0044628237\n",
      "Epoch [3040/10000], Training Loss: 0.0001765127, Validation Loss: 0.0049009458\n",
      "Epoch [3060/10000], Training Loss: 0.0000612084, Validation Loss: 0.0046759346\n",
      "Epoch [3080/10000], Training Loss: 0.0000402363, Validation Loss: 0.0045562722\n",
      "Epoch [3100/10000], Training Loss: 0.0001372407, Validation Loss: 0.0043412345\n",
      "Epoch [3120/10000], Training Loss: 0.0000423630, Validation Loss: 0.0044694659\n",
      "Epoch [3140/10000], Training Loss: 0.0000409374, Validation Loss: 0.0045333044\n",
      "Epoch [3160/10000], Training Loss: 0.0000347508, Validation Loss: 0.0045417654\n",
      "Epoch [3180/10000], Training Loss: 0.0000345143, Validation Loss: 0.0045048478\n",
      "Epoch [3200/10000], Training Loss: 0.0000492413, Validation Loss: 0.0044180080\n",
      "Epoch [3220/10000], Training Loss: 0.0003427597, Validation Loss: 0.0050861947\n",
      "Epoch [3240/10000], Training Loss: 0.0000636386, Validation Loss: 0.0045441496\n",
      "Epoch [3260/10000], Training Loss: 0.0000379439, Validation Loss: 0.0046005393\n",
      "Epoch [3280/10000], Training Loss: 0.0000347150, Validation Loss: 0.0045513641\n",
      "Epoch [3300/10000], Training Loss: 0.0000338266, Validation Loss: 0.0045343763\n",
      "Epoch [3320/10000], Training Loss: 0.0000333655, Validation Loss: 0.0045130812\n",
      "Epoch [3340/10000], Training Loss: 0.0000379681, Validation Loss: 0.0045440844\n",
      "Epoch [3360/10000], Training Loss: 0.0004486887, Validation Loss: 0.0046830527\n",
      "Epoch [3380/10000], Training Loss: 0.0000849739, Validation Loss: 0.0049605565\n",
      "Epoch [3400/10000], Training Loss: 0.0000440039, Validation Loss: 0.0046700756\n",
      "Epoch [3420/10000], Training Loss: 0.0000355541, Validation Loss: 0.0046122875\n",
      "Epoch [3440/10000], Training Loss: 0.0000345127, Validation Loss: 0.0046109380\n",
      "Epoch [3460/10000], Training Loss: 0.0000338702, Validation Loss: 0.0045886235\n",
      "Epoch [3480/10000], Training Loss: 0.0000334289, Validation Loss: 0.0045771310\n",
      "Epoch [3500/10000], Training Loss: 0.0000330627, Validation Loss: 0.0045610177\n",
      "Epoch [3520/10000], Training Loss: 0.0000330931, Validation Loss: 0.0045478535\n",
      "Epoch [3540/10000], Training Loss: 0.0000838416, Validation Loss: 0.0049616196\n",
      "Epoch [3560/10000], Training Loss: 0.0000874244, Validation Loss: 0.0046156929\n",
      "Epoch [3580/10000], Training Loss: 0.0000397589, Validation Loss: 0.0046371692\n",
      "Epoch [3600/10000], Training Loss: 0.0000970981, Validation Loss: 0.0049229600\n",
      "Epoch [3620/10000], Training Loss: 0.0000531947, Validation Loss: 0.0048100282\n",
      "Epoch [3640/10000], Training Loss: 0.0000430514, Validation Loss: 0.0045780190\n",
      "Epoch [3660/10000], Training Loss: 0.0000333719, Validation Loss: 0.0045811720\n",
      "Epoch [3680/10000], Training Loss: 0.0000329136, Validation Loss: 0.0045683975\n",
      "Epoch [3700/10000], Training Loss: 0.0000344741, Validation Loss: 0.0045756130\n",
      "Epoch [3720/10000], Training Loss: 0.0004410044, Validation Loss: 0.0048856637\n",
      "Epoch [3740/10000], Training Loss: 0.0000711881, Validation Loss: 0.0046772501\n",
      "Epoch [3760/10000], Training Loss: 0.0000355614, Validation Loss: 0.0046308869\n",
      "Epoch [3780/10000], Training Loss: 0.0000330240, Validation Loss: 0.0045441673\n",
      "Epoch [3800/10000], Training Loss: 0.0000322968, Validation Loss: 0.0045501501\n",
      "Epoch [3820/10000], Training Loss: 0.0000318139, Validation Loss: 0.0045503727\n",
      "Epoch [3840/10000], Training Loss: 0.0000329898, Validation Loss: 0.0045704874\n",
      "Epoch [3860/10000], Training Loss: 0.0001536990, Validation Loss: 0.0044528036\n",
      "Epoch [3880/10000], Training Loss: 0.0000590536, Validation Loss: 0.0044697807\n",
      "Epoch [3900/10000], Training Loss: 0.0000364075, Validation Loss: 0.0045071980\n",
      "Epoch [3920/10000], Training Loss: 0.0000331747, Validation Loss: 0.0045786956\n",
      "Epoch [3940/10000], Training Loss: 0.0000320269, Validation Loss: 0.0045793052\n",
      "Epoch [3960/10000], Training Loss: 0.0000315664, Validation Loss: 0.0045543313\n",
      "Epoch [3980/10000], Training Loss: 0.0000676196, Validation Loss: 0.0046230261\n",
      "Epoch [4000/10000], Training Loss: 0.0001787042, Validation Loss: 0.0051408778\n",
      "Epoch [4020/10000], Training Loss: 0.0000469609, Validation Loss: 0.0046879491\n",
      "Epoch [4040/10000], Training Loss: 0.0000325549, Validation Loss: 0.0046129646\n",
      "Epoch [4060/10000], Training Loss: 0.0000447154, Validation Loss: 0.0046505718\n",
      "Epoch [4080/10000], Training Loss: 0.0001136858, Validation Loss: 0.0044626971\n",
      "Epoch [4100/10000], Training Loss: 0.0000433440, Validation Loss: 0.0044933795\n",
      "Epoch [4120/10000], Training Loss: 0.0000350953, Validation Loss: 0.0045601153\n",
      "Epoch [4140/10000], Training Loss: 0.0000764196, Validation Loss: 0.0047230716\n",
      "Epoch [4160/10000], Training Loss: 0.0001644690, Validation Loss: 0.0044075740\n",
      "Epoch [4180/10000], Training Loss: 0.0000427372, Validation Loss: 0.0046410295\n",
      "Epoch [4200/10000], Training Loss: 0.0000336816, Validation Loss: 0.0045826561\n",
      "Epoch [4220/10000], Training Loss: 0.0000309292, Validation Loss: 0.0045345305\n",
      "Epoch [4240/10000], Training Loss: 0.0000335188, Validation Loss: 0.0045398129\n",
      "Epoch [4260/10000], Training Loss: 0.0002767706, Validation Loss: 0.0045527732\n",
      "Epoch [4280/10000], Training Loss: 0.0000486413, Validation Loss: 0.0046255444\n",
      "Epoch [4300/10000], Training Loss: 0.0000514348, Validation Loss: 0.0045204917\n",
      "Epoch [4320/10000], Training Loss: 0.0000337910, Validation Loss: 0.0045825811\n",
      "Epoch [4340/10000], Training Loss: 0.0000307803, Validation Loss: 0.0045854021\n",
      "Epoch [4360/10000], Training Loss: 0.0000304926, Validation Loss: 0.0045389221\n",
      "Epoch [4380/10000], Training Loss: 0.0013206773, Validation Loss: 0.0044265408\n",
      "Epoch [4400/10000], Training Loss: 0.0001089884, Validation Loss: 0.0045688031\n",
      "Epoch [4420/10000], Training Loss: 0.0000439183, Validation Loss: 0.0045902985\n",
      "Epoch [4440/10000], Training Loss: 0.0000329045, Validation Loss: 0.0045734886\n",
      "Epoch [4460/10000], Training Loss: 0.0000309221, Validation Loss: 0.0046207197\n",
      "Epoch [4480/10000], Training Loss: 0.0000302746, Validation Loss: 0.0045873239\n",
      "Epoch [4500/10000], Training Loss: 0.0000299002, Validation Loss: 0.0045724511\n",
      "Epoch [4520/10000], Training Loss: 0.0000295895, Validation Loss: 0.0045610270\n",
      "Epoch [4540/10000], Training Loss: 0.0000300772, Validation Loss: 0.0045588166\n",
      "Epoch [4560/10000], Training Loss: 0.0006242692, Validation Loss: 0.0052203410\n",
      "Epoch [4580/10000], Training Loss: 0.0000497575, Validation Loss: 0.0045101591\n",
      "Epoch [4600/10000], Training Loss: 0.0000399220, Validation Loss: 0.0046016085\n",
      "Epoch [4620/10000], Training Loss: 0.0000320780, Validation Loss: 0.0045953719\n",
      "Epoch [4640/10000], Training Loss: 0.0000302814, Validation Loss: 0.0045938394\n",
      "Epoch [4660/10000], Training Loss: 0.0000297821, Validation Loss: 0.0045945682\n",
      "Epoch [4680/10000], Training Loss: 0.0000294170, Validation Loss: 0.0045747040\n",
      "Epoch [4700/10000], Training Loss: 0.0000291217, Validation Loss: 0.0045631644\n",
      "Epoch [4720/10000], Training Loss: 0.0000734174, Validation Loss: 0.0046261647\n",
      "Epoch [4740/10000], Training Loss: 0.0001537581, Validation Loss: 0.0049829124\n",
      "Epoch [4760/10000], Training Loss: 0.0000618804, Validation Loss: 0.0046104640\n",
      "Epoch [4780/10000], Training Loss: 0.0000350988, Validation Loss: 0.0047107562\n",
      "Epoch [4800/10000], Training Loss: 0.0000305514, Validation Loss: 0.0046751346\n",
      "Epoch [4820/10000], Training Loss: 0.0000296927, Validation Loss: 0.0046792468\n",
      "Epoch [4840/10000], Training Loss: 0.0000292683, Validation Loss: 0.0046516247\n",
      "Epoch [4860/10000], Training Loss: 0.0000289465, Validation Loss: 0.0046349945\n",
      "Epoch [4880/10000], Training Loss: 0.0000296005, Validation Loss: 0.0046436442\n",
      "Epoch [4900/10000], Training Loss: 0.0001724403, Validation Loss: 0.0046538911\n",
      "Epoch [4920/10000], Training Loss: 0.0000577506, Validation Loss: 0.0046407152\n",
      "Epoch [4940/10000], Training Loss: 0.0000317962, Validation Loss: 0.0046458077\n",
      "Epoch [4960/10000], Training Loss: 0.0000309604, Validation Loss: 0.0046603647\n",
      "Epoch [4980/10000], Training Loss: 0.0000293034, Validation Loss: 0.0046377741\n",
      "Epoch [5000/10000], Training Loss: 0.0000288135, Validation Loss: 0.0046324157\n",
      "Epoch [5020/10000], Training Loss: 0.0000284812, Validation Loss: 0.0046252096\n",
      "Epoch [5040/10000], Training Loss: 0.0000282213, Validation Loss: 0.0046190955\n",
      "Epoch [5060/10000], Training Loss: 0.0003317752, Validation Loss: 0.0054032127\n",
      "Epoch [5080/10000], Training Loss: 0.0000830806, Validation Loss: 0.0049875695\n",
      "Epoch [5100/10000], Training Loss: 0.0000378183, Validation Loss: 0.0047830516\n",
      "Epoch [5120/10000], Training Loss: 0.0000332270, Validation Loss: 0.0047277422\n",
      "Epoch [5140/10000], Training Loss: 0.0000293113, Validation Loss: 0.0047186739\n",
      "Epoch [5160/10000], Training Loss: 0.0000287546, Validation Loss: 0.0047007296\n",
      "Epoch [5180/10000], Training Loss: 0.0000286799, Validation Loss: 0.0046720128\n",
      "Epoch [5200/10000], Training Loss: 0.0003605339, Validation Loss: 0.0044777682\n",
      "Epoch [5220/10000], Training Loss: 0.0000475064, Validation Loss: 0.0045310250\n",
      "Epoch [5240/10000], Training Loss: 0.0000313628, Validation Loss: 0.0046204380\n",
      "Epoch [5260/10000], Training Loss: 0.0000293066, Validation Loss: 0.0046902662\n",
      "Epoch [5280/10000], Training Loss: 0.0000281826, Validation Loss: 0.0046357205\n",
      "Epoch [5300/10000], Training Loss: 0.0000277774, Validation Loss: 0.0046400060\n",
      "Epoch [5320/10000], Training Loss: 0.0000278607, Validation Loss: 0.0046185586\n",
      "Epoch [5340/10000], Training Loss: 0.0011263757, Validation Loss: 0.0045077875\n",
      "Epoch [5360/10000], Training Loss: 0.0001099348, Validation Loss: 0.0044915816\n",
      "Epoch [5380/10000], Training Loss: 0.0000392120, Validation Loss: 0.0046872315\n",
      "Epoch [5400/10000], Training Loss: 0.0000294812, Validation Loss: 0.0047059758\n",
      "Epoch [5420/10000], Training Loss: 0.0000284555, Validation Loss: 0.0047158278\n",
      "Epoch [5440/10000], Training Loss: 0.0000278595, Validation Loss: 0.0047061159\n",
      "Epoch [5460/10000], Training Loss: 0.0000275248, Validation Loss: 0.0046909656\n",
      "Epoch [5480/10000], Training Loss: 0.0000363393, Validation Loss: 0.0046997047\n",
      "Epoch [5500/10000], Training Loss: 0.0001026599, Validation Loss: 0.0045496058\n",
      "Epoch [5520/10000], Training Loss: 0.0000362962, Validation Loss: 0.0047258958\n",
      "Epoch [5540/10000], Training Loss: 0.0000301027, Validation Loss: 0.0047114757\n",
      "Epoch [5560/10000], Training Loss: 0.0000339770, Validation Loss: 0.0046247533\n",
      "Epoch [5580/10000], Training Loss: 0.0001841226, Validation Loss: 0.0048495284\n",
      "Epoch [5600/10000], Training Loss: 0.0000377539, Validation Loss: 0.0047428343\n",
      "Epoch [5620/10000], Training Loss: 0.0000313874, Validation Loss: 0.0048206490\n",
      "Epoch [5640/10000], Training Loss: 0.0000278763, Validation Loss: 0.0047788159\n",
      "Epoch [5660/10000], Training Loss: 0.0000272698, Validation Loss: 0.0047680927\n",
      "Epoch [5680/10000], Training Loss: 0.0000277372, Validation Loss: 0.0047563538\n",
      "Epoch [5700/10000], Training Loss: 0.0004065705, Validation Loss: 0.0054692063\n",
      "Epoch [5720/10000], Training Loss: 0.0000591258, Validation Loss: 0.0045571416\n",
      "Epoch [5740/10000], Training Loss: 0.0000310604, Validation Loss: 0.0047274567\n",
      "Epoch [5760/10000], Training Loss: 0.0000275348, Validation Loss: 0.0047110938\n",
      "Epoch [5780/10000], Training Loss: 0.0000269111, Validation Loss: 0.0047144215\n",
      "Epoch [5800/10000], Training Loss: 0.0003280459, Validation Loss: 0.0044856719\n",
      "Epoch [5820/10000], Training Loss: 0.0000544321, Validation Loss: 0.0050020986\n",
      "Epoch [5840/10000], Training Loss: 0.0000384079, Validation Loss: 0.0047923508\n",
      "Epoch [5860/10000], Training Loss: 0.0000282129, Validation Loss: 0.0048337844\n",
      "Epoch [5880/10000], Training Loss: 0.0000270342, Validation Loss: 0.0048095584\n",
      "Epoch [5900/10000], Training Loss: 0.0003275939, Validation Loss: 0.0053035212\n",
      "Epoch [5920/10000], Training Loss: 0.0000699675, Validation Loss: 0.0049030143\n",
      "Epoch [5940/10000], Training Loss: 0.0000314462, Validation Loss: 0.0049152626\n",
      "Epoch [5960/10000], Training Loss: 0.0000273882, Validation Loss: 0.0047526844\n",
      "Epoch [5980/10000], Training Loss: 0.0000263957, Validation Loss: 0.0047846260\n",
      "Epoch [6000/10000], Training Loss: 0.0002755277, Validation Loss: 0.0054876874\n",
      "Epoch [6020/10000], Training Loss: 0.0001224819, Validation Loss: 0.0047540632\n",
      "Epoch [6040/10000], Training Loss: 0.0000421784, Validation Loss: 0.0048515694\n",
      "Epoch [6060/10000], Training Loss: 0.0000282166, Validation Loss: 0.0048889704\n",
      "Epoch [6080/10000], Training Loss: 0.0000267211, Validation Loss: 0.0048627141\n",
      "Epoch [6100/10000], Training Loss: 0.0000269856, Validation Loss: 0.0048595229\n",
      "Epoch [6120/10000], Training Loss: 0.0002913227, Validation Loss: 0.0054303142\n",
      "Epoch [6140/10000], Training Loss: 0.0000529122, Validation Loss: 0.0046818354\n",
      "Epoch [6160/10000], Training Loss: 0.0000299990, Validation Loss: 0.0048522386\n",
      "Epoch [6180/10000], Training Loss: 0.0000265901, Validation Loss: 0.0048001776\n",
      "Epoch [6200/10000], Training Loss: 0.0000292410, Validation Loss: 0.0048633846\n",
      "Epoch [6220/10000], Training Loss: 0.0000887749, Validation Loss: 0.0048550614\n",
      "Epoch [6240/10000], Training Loss: 0.0000542619, Validation Loss: 0.0050615780\n",
      "Epoch [6260/10000], Training Loss: 0.0000296651, Validation Loss: 0.0048557222\n",
      "Epoch [6280/10000], Training Loss: 0.0000263810, Validation Loss: 0.0049002278\n",
      "Epoch [6300/10000], Training Loss: 0.0000472019, Validation Loss: 0.0048236577\n",
      "Epoch [6320/10000], Training Loss: 0.0000743195, Validation Loss: 0.0051612644\n",
      "Epoch [6340/10000], Training Loss: 0.0000391542, Validation Loss: 0.0047746478\n",
      "Epoch [6360/10000], Training Loss: 0.0000279128, Validation Loss: 0.0049207527\n",
      "Epoch [6380/10000], Training Loss: 0.0000968741, Validation Loss: 0.0052080764\n",
      "Epoch [6400/10000], Training Loss: 0.0001190888, Validation Loss: 0.0051162099\n",
      "Epoch [6420/10000], Training Loss: 0.0000426998, Validation Loss: 0.0048573180\n",
      "Epoch [6440/10000], Training Loss: 0.0000281007, Validation Loss: 0.0049605528\n",
      "Epoch [6460/10000], Training Loss: 0.0000362047, Validation Loss: 0.0049828431\n",
      "Epoch [6480/10000], Training Loss: 0.0000975404, Validation Loss: 0.0047644903\n",
      "Epoch [6500/10000], Training Loss: 0.0000311694, Validation Loss: 0.0049066427\n",
      "Epoch [6520/10000], Training Loss: 0.0000287867, Validation Loss: 0.0048790844\n",
      "Epoch [6540/10000], Training Loss: 0.0001388454, Validation Loss: 0.0046421606\n",
      "Epoch [6560/10000], Training Loss: 0.0000806244, Validation Loss: 0.0048653460\n",
      "Epoch [6580/10000], Training Loss: 0.0000289643, Validation Loss: 0.0049858894\n",
      "Epoch [6600/10000], Training Loss: 0.0000288263, Validation Loss: 0.0050021620\n",
      "Epoch [6620/10000], Training Loss: 0.0001104280, Validation Loss: 0.0052750222\n",
      "Epoch [6640/10000], Training Loss: 0.0000440970, Validation Loss: 0.0048354343\n",
      "Epoch [6660/10000], Training Loss: 0.0000273903, Validation Loss: 0.0049264459\n",
      "Epoch [6680/10000], Training Loss: 0.0000695354, Validation Loss: 0.0047390130\n",
      "Epoch [6700/10000], Training Loss: 0.0000998686, Validation Loss: 0.0049021468\n",
      "Epoch [6720/10000], Training Loss: 0.0000443914, Validation Loss: 0.0051288535\n",
      "Epoch [6740/10000], Training Loss: 0.0000287638, Validation Loss: 0.0049418476\n",
      "Epoch [6760/10000], Training Loss: 0.0000565014, Validation Loss: 0.0048965784\n",
      "Epoch [6780/10000], Training Loss: 0.0000744326, Validation Loss: 0.0052385600\n",
      "Epoch [6800/10000], Training Loss: 0.0000309675, Validation Loss: 0.0049177366\n",
      "Epoch [6820/10000], Training Loss: 0.0000297873, Validation Loss: 0.0049963738\n",
      "Epoch [6840/10000], Training Loss: 0.0002336451, Validation Loss: 0.0052676629\n",
      "Epoch [6860/10000], Training Loss: 0.0000503214, Validation Loss: 0.0049081463\n",
      "Epoch [6880/10000], Training Loss: 0.0000265092, Validation Loss: 0.0049643945\n",
      "Epoch [6900/10000], Training Loss: 0.0000274897, Validation Loss: 0.0049452670\n",
      "Epoch [6920/10000], Training Loss: 0.0002500392, Validation Loss: 0.0051940447\n",
      "Epoch [6940/10000], Training Loss: 0.0000578385, Validation Loss: 0.0049624201\n",
      "Epoch [6960/10000], Training Loss: 0.0000289488, Validation Loss: 0.0049587931\n",
      "Epoch [6980/10000], Training Loss: 0.0004846045, Validation Loss: 0.0046473658\n",
      "Epoch [7000/10000], Training Loss: 0.0000707764, Validation Loss: 0.0052183615\n",
      "Epoch [7020/10000], Training Loss: 0.0000269763, Validation Loss: 0.0050960761\n",
      "Epoch [7040/10000], Training Loss: 0.0000251127, Validation Loss: 0.0050387755\n",
      "Epoch [7060/10000], Training Loss: 0.0000243495, Validation Loss: 0.0050213579\n",
      "Epoch [7080/10000], Training Loss: 0.0000473294, Validation Loss: 0.0049213981\n",
      "Epoch [7100/10000], Training Loss: 0.0001174232, Validation Loss: 0.0052966774\n",
      "Epoch [7120/10000], Training Loss: 0.0000279098, Validation Loss: 0.0050188005\n",
      "Epoch [7140/10000], Training Loss: 0.0000269611, Validation Loss: 0.0050004967\n",
      "Epoch [7160/10000], Training Loss: 0.0000384037, Validation Loss: 0.0049057198\n",
      "Epoch [7180/10000], Training Loss: 0.0002033693, Validation Loss: 0.0053587100\n",
      "Epoch [7200/10000], Training Loss: 0.0000499004, Validation Loss: 0.0049842619\n",
      "Epoch [7220/10000], Training Loss: 0.0000279302, Validation Loss: 0.0051540732\n",
      "Epoch [7240/10000], Training Loss: 0.0000928536, Validation Loss: 0.0052546458\n",
      "Epoch [7260/10000], Training Loss: 0.0000460814, Validation Loss: 0.0048825587\n",
      "Epoch [7280/10000], Training Loss: 0.0000271522, Validation Loss: 0.0050617908\n",
      "Epoch [7300/10000], Training Loss: 0.0000399203, Validation Loss: 0.0051643453\n",
      "Epoch [7320/10000], Training Loss: 0.0001575795, Validation Loss: 0.0049396213\n",
      "Epoch [7340/10000], Training Loss: 0.0000414466, Validation Loss: 0.0052484213\n",
      "Epoch [7360/10000], Training Loss: 0.0000264748, Validation Loss: 0.0050712815\n",
      "Epoch [7380/10000], Training Loss: 0.0000497319, Validation Loss: 0.0049922196\n",
      "Epoch [7400/10000], Training Loss: 0.0000818406, Validation Loss: 0.0053677112\n",
      "Epoch [7420/10000], Training Loss: 0.0000295234, Validation Loss: 0.0049769082\n",
      "Epoch [7440/10000], Training Loss: 0.0000261822, Validation Loss: 0.0050532878\n",
      "Epoch [7460/10000], Training Loss: 0.0004150484, Validation Loss: 0.0057753879\n",
      "Epoch [7480/10000], Training Loss: 0.0000436072, Validation Loss: 0.0050544925\n",
      "Epoch [7500/10000], Training Loss: 0.0000256682, Validation Loss: 0.0051131579\n",
      "Epoch [7520/10000], Training Loss: 0.0000639915, Validation Loss: 0.0050281589\n",
      "Epoch [7540/10000], Training Loss: 0.0000644684, Validation Loss: 0.0053337123\n",
      "Epoch [7560/10000], Training Loss: 0.0000325325, Validation Loss: 0.0050526033\n",
      "Epoch [7580/10000], Training Loss: 0.0000784283, Validation Loss: 0.0048947297\n",
      "Epoch [7600/10000], Training Loss: 0.0000860738, Validation Loss: 0.0052636475\n",
      "Epoch [7620/10000], Training Loss: 0.0000276309, Validation Loss: 0.0051407758\n",
      "Epoch [7640/10000], Training Loss: 0.0000438532, Validation Loss: 0.0051927543\n",
      "Epoch [7660/10000], Training Loss: 0.0000733276, Validation Loss: 0.0049441401\n",
      "Epoch [7680/10000], Training Loss: 0.0000372953, Validation Loss: 0.0051682340\n",
      "Epoch [7700/10000], Training Loss: 0.0000254634, Validation Loss: 0.0050946190\n",
      "Epoch [7720/10000], Training Loss: 0.0004889130, Validation Loss: 0.0056203641\n",
      "Epoch [7740/10000], Training Loss: 0.0000642419, Validation Loss: 0.0053628320\n",
      "Epoch [7760/10000], Training Loss: 0.0000277902, Validation Loss: 0.0052431165\n",
      "Epoch [7780/10000], Training Loss: 0.0000245684, Validation Loss: 0.0052206391\n",
      "Epoch [7800/10000], Training Loss: 0.0000286212, Validation Loss: 0.0051472671\n",
      "Epoch [7820/10000], Training Loss: 0.0000810683, Validation Loss: 0.0051807975\n",
      "Epoch [7840/10000], Training Loss: 0.0000325129, Validation Loss: 0.0051720617\n",
      "Epoch [7860/10000], Training Loss: 0.0000237342, Validation Loss: 0.0051585468\n",
      "Epoch [7880/10000], Training Loss: 0.0000825704, Validation Loss: 0.0054055592\n",
      "Epoch [7900/10000], Training Loss: 0.0000766675, Validation Loss: 0.0052618473\n",
      "Epoch [7920/10000], Training Loss: 0.0000265247, Validation Loss: 0.0050461167\n",
      "Epoch [7940/10000], Training Loss: 0.0000247124, Validation Loss: 0.0051120846\n",
      "Epoch [7960/10000], Training Loss: 0.0000227644, Validation Loss: 0.0051128687\n",
      "Epoch [7980/10000], Training Loss: 0.0000230424, Validation Loss: 0.0051343981\n",
      "Epoch [8000/10000], Training Loss: 0.0003533268, Validation Loss: 0.0052020894\n",
      "Epoch [8020/10000], Training Loss: 0.0000634848, Validation Loss: 0.0053771269\n",
      "Epoch [8040/10000], Training Loss: 0.0000265282, Validation Loss: 0.0053123320\n",
      "Epoch [8060/10000], Training Loss: 0.0000236914, Validation Loss: 0.0052699447\n",
      "Epoch [8080/10000], Training Loss: 0.0001393228, Validation Loss: 0.0051614149\n",
      "Epoch [8100/10000], Training Loss: 0.0000594759, Validation Loss: 0.0050592385\n",
      "Epoch [8120/10000], Training Loss: 0.0000289958, Validation Loss: 0.0051296265\n",
      "Epoch [8140/10000], Training Loss: 0.0000231490, Validation Loss: 0.0051475111\n",
      "Epoch [8160/10000], Training Loss: 0.0000220230, Validation Loss: 0.0051581361\n",
      "Epoch [8180/10000], Training Loss: 0.0000218437, Validation Loss: 0.0051498888\n",
      "Epoch [8200/10000], Training Loss: 0.0009799607, Validation Loss: 0.0066905976\n",
      "Epoch [8220/10000], Training Loss: 0.0000654117, Validation Loss: 0.0054449872\n",
      "Epoch [8240/10000], Training Loss: 0.0000281456, Validation Loss: 0.0051637692\n",
      "Epoch [8260/10000], Training Loss: 0.0000247294, Validation Loss: 0.0051404550\n",
      "Epoch [8280/10000], Training Loss: 0.0000227167, Validation Loss: 0.0051565082\n",
      "Epoch [8300/10000], Training Loss: 0.0000221331, Validation Loss: 0.0051581482\n",
      "Epoch [8320/10000], Training Loss: 0.0000218543, Validation Loss: 0.0051532183\n",
      "Epoch [8340/10000], Training Loss: 0.0000218887, Validation Loss: 0.0051335595\n",
      "Epoch [8360/10000], Training Loss: 0.0003256956, Validation Loss: 0.0051692864\n",
      "Epoch [8380/10000], Training Loss: 0.0000316025, Validation Loss: 0.0054855426\n",
      "Epoch [8400/10000], Training Loss: 0.0000259996, Validation Loss: 0.0054106102\n",
      "Epoch [8420/10000], Training Loss: 0.0000363385, Validation Loss: 0.0053441301\n",
      "Epoch [8440/10000], Training Loss: 0.0000481261, Validation Loss: 0.0051713334\n",
      "Epoch [8460/10000], Training Loss: 0.0000229555, Validation Loss: 0.0052452944\n",
      "Epoch [8480/10000], Training Loss: 0.0000265832, Validation Loss: 0.0051797363\n",
      "Epoch [8500/10000], Training Loss: 0.0001673232, Validation Loss: 0.0050504445\n",
      "Epoch [8520/10000], Training Loss: 0.0000310193, Validation Loss: 0.0051924703\n",
      "Epoch [8540/10000], Training Loss: 0.0000256647, Validation Loss: 0.0051169172\n",
      "Epoch [8560/10000], Training Loss: 0.0001161369, Validation Loss: 0.0049671102\n",
      "Epoch [8580/10000], Training Loss: 0.0000362074, Validation Loss: 0.0051490297\n",
      "Epoch [8600/10000], Training Loss: 0.0000245554, Validation Loss: 0.0051532970\n",
      "Epoch [8620/10000], Training Loss: 0.0000239700, Validation Loss: 0.0052150791\n",
      "Epoch [8640/10000], Training Loss: 0.0001241383, Validation Loss: 0.0052778111\n",
      "Epoch [8660/10000], Training Loss: 0.0000345629, Validation Loss: 0.0053618005\n",
      "Epoch [8680/10000], Training Loss: 0.0000250558, Validation Loss: 0.0052275383\n",
      "Epoch [8700/10000], Training Loss: 0.0003266676, Validation Loss: 0.0058382466\n",
      "Epoch [8720/10000], Training Loss: 0.0000494800, Validation Loss: 0.0052889232\n",
      "Epoch [8740/10000], Training Loss: 0.0000235535, Validation Loss: 0.0052816491\n",
      "Epoch [8760/10000], Training Loss: 0.0000215616, Validation Loss: 0.0052193208\n",
      "Epoch [8780/10000], Training Loss: 0.0001060356, Validation Loss: 0.0050458428\n",
      "Epoch [8800/10000], Training Loss: 0.0000450335, Validation Loss: 0.0051624430\n",
      "Epoch [8820/10000], Training Loss: 0.0000292989, Validation Loss: 0.0051981392\n",
      "Epoch [8840/10000], Training Loss: 0.0000221405, Validation Loss: 0.0051954654\n",
      "Epoch [8860/10000], Training Loss: 0.0000254578, Validation Loss: 0.0051567103\n",
      "Epoch [8880/10000], Training Loss: 0.0001584005, Validation Loss: 0.0056765396\n",
      "Epoch [8900/10000], Training Loss: 0.0000466782, Validation Loss: 0.0052850698\n",
      "Epoch [8920/10000], Training Loss: 0.0000480328, Validation Loss: 0.0054199258\n",
      "Epoch [8940/10000], Training Loss: 0.0000235691, Validation Loss: 0.0053085159\n",
      "Epoch [8960/10000], Training Loss: 0.0000800648, Validation Loss: 0.0051203915\n",
      "Epoch [8980/10000], Training Loss: 0.0000379510, Validation Loss: 0.0053470293\n",
      "Epoch [9000/10000], Training Loss: 0.0000228186, Validation Loss: 0.0052510155\n",
      "Epoch [9020/10000], Training Loss: 0.0001782807, Validation Loss: 0.0056610676\n",
      "Epoch [9040/10000], Training Loss: 0.0001114518, Validation Loss: 0.0054940660\n",
      "Epoch [9060/10000], Training Loss: 0.0000251013, Validation Loss: 0.0051855459\n",
      "Epoch [9080/10000], Training Loss: 0.0000221296, Validation Loss: 0.0052095857\n",
      "Epoch [9100/10000], Training Loss: 0.0000213823, Validation Loss: 0.0051905354\n",
      "Epoch [9120/10000], Training Loss: 0.0003993017, Validation Loss: 0.0051364074\n",
      "Epoch [9140/10000], Training Loss: 0.0000371597, Validation Loss: 0.0054239794\n",
      "Epoch [9160/10000], Training Loss: 0.0000650474, Validation Loss: 0.0054975902\n",
      "Epoch [9180/10000], Training Loss: 0.0000493032, Validation Loss: 0.0051787109\n",
      "Epoch [9200/10000], Training Loss: 0.0000308784, Validation Loss: 0.0053494191\n",
      "Epoch [9220/10000], Training Loss: 0.0001084329, Validation Loss: 0.0055488967\n",
      "Epoch [9240/10000], Training Loss: 0.0000366150, Validation Loss: 0.0052042366\n",
      "Epoch [9260/10000], Training Loss: 0.0000219043, Validation Loss: 0.0052609919\n",
      "Epoch [9280/10000], Training Loss: 0.0003449222, Validation Loss: 0.0059613227\n",
      "Epoch [9300/10000], Training Loss: 0.0000759499, Validation Loss: 0.0054079248\n",
      "Epoch [9320/10000], Training Loss: 0.0000354211, Validation Loss: 0.0053159557\n",
      "Epoch [9340/10000], Training Loss: 0.0000218882, Validation Loss: 0.0053169103\n",
      "Epoch [9360/10000], Training Loss: 0.0000203747, Validation Loss: 0.0052716439\n",
      "Epoch [9380/10000], Training Loss: 0.0000201501, Validation Loss: 0.0052629383\n",
      "Epoch [9400/10000], Training Loss: 0.0001070326, Validation Loss: 0.0050025182\n",
      "Epoch [9420/10000], Training Loss: 0.0000885814, Validation Loss: 0.0053187320\n",
      "Epoch [9440/10000], Training Loss: 0.0000353691, Validation Loss: 0.0053038136\n",
      "Epoch [9460/10000], Training Loss: 0.0000213331, Validation Loss: 0.0053424765\n",
      "Epoch [9480/10000], Training Loss: 0.0000206604, Validation Loss: 0.0052871602\n",
      "Epoch [9500/10000], Training Loss: 0.0000863895, Validation Loss: 0.0052448399\n",
      "Epoch [9520/10000], Training Loss: 0.0000616017, Validation Loss: 0.0053299307\n",
      "Epoch [9540/10000], Training Loss: 0.0000264093, Validation Loss: 0.0052670720\n",
      "Epoch [9560/10000], Training Loss: 0.0000201010, Validation Loss: 0.0052591497\n",
      "Epoch [9580/10000], Training Loss: 0.0000848499, Validation Loss: 0.0054983897\n",
      "Epoch [9600/10000], Training Loss: 0.0001454800, Validation Loss: 0.0054784687\n",
      "Epoch [9620/10000], Training Loss: 0.0000275111, Validation Loss: 0.0054658684\n",
      "Epoch [9640/10000], Training Loss: 0.0000230839, Validation Loss: 0.0053334581\n",
      "Epoch [9660/10000], Training Loss: 0.0000562777, Validation Loss: 0.0054492191\n",
      "Epoch [9680/10000], Training Loss: 0.0000337036, Validation Loss: 0.0051960126\n",
      "Epoch [9700/10000], Training Loss: 0.0000229758, Validation Loss: 0.0053081647\n",
      "Epoch [9720/10000], Training Loss: 0.0000373004, Validation Loss: 0.0054092109\n",
      "Epoch [9740/10000], Training Loss: 0.0001264815, Validation Loss: 0.0051234765\n",
      "Epoch [9760/10000], Training Loss: 0.0000232560, Validation Loss: 0.0053557274\n",
      "Epoch [9780/10000], Training Loss: 0.0000209248, Validation Loss: 0.0052725468\n",
      "Epoch [9800/10000], Training Loss: 0.0001579062, Validation Loss: 0.0050705224\n",
      "Epoch [9820/10000], Training Loss: 0.0000664815, Validation Loss: 0.0052480958\n",
      "Epoch [9840/10000], Training Loss: 0.0000224902, Validation Loss: 0.0053561730\n",
      "Epoch [9860/10000], Training Loss: 0.0000244561, Validation Loss: 0.0052852877\n",
      "Epoch [9880/10000], Training Loss: 0.0000868741, Validation Loss: 0.0056196712\n",
      "Epoch [9900/10000], Training Loss: 0.0000351935, Validation Loss: 0.0051955101\n",
      "Epoch [9920/10000], Training Loss: 0.0000207983, Validation Loss: 0.0052789254\n",
      "Epoch [9940/10000], Training Loss: 0.0000669775, Validation Loss: 0.0055409851\n",
      "Epoch [9960/10000], Training Loss: 0.0000228226, Validation Loss: 0.0054484433\n",
      "Epoch [9980/10000], Training Loss: 0.0000245109, Validation Loss: 0.0053837881\n",
      "Epoch [10000/10000], Training Loss: 0.0001398009, Validation Loss: 0.0052120010\n",
      "Training finished!\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10000\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(0, 1):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(x_train, lengths)\n",
    "        loss = criterion(outputs, y_train)\n",
    "\n",
    "        # Backpropagation and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(x_validation, lengths_val)\n",
    "            val_loss = criterion(val_outputs, y_validation)\n",
    "    \n",
    "    \n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {loss.item():.10f}, Validation Loss: {val_loss.item():.10f}')\n",
    "\n",
    "print(\"Training finished!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T20:28:22.872882389Z",
     "start_time": "2023-08-29T20:27:52.892697262Z"
    }
   },
   "id": "90632fa906349db9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
